---
title: "Porewater CDOM processing script"
author: "AMP"
date: "`r Sys.Date()`"
output: html_document
---

***Note: Date times break for an unknown reason even after setting the system time in the setup IF your computer time is NOT on eastern timezone. so, you need to change that if you're not living in eastern time on your computer to prevent this unknown issue from really messing with the data.*** 

This script imports corrected absorbance and fluorescence indicies from the Aqualog at PNNL MCRL and exports clean, Level 1 QC'ed data.
Data are currently corrected in matlab, where corrected datasets and computed indicies files are then exported.
L0 data lives on google drive.
The indicies data that are used herein should be located at some point in the google drive. They currently live in the MCRL sharedrive and on github. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, 
                      message = F,
                      warning = F)

# load packages
require(pacman)
pacman::p_load(tidyverse, # keep things tidy
               janitor, # useful for simplifying column names
               googlesheets4, # read_sheet 
               googledrive, # drive_ functions
               plotrix,
               here) 

#Try to deal with the timezone demons 
common_tz = "Etc/GMT+5"

Sys.setenv(TZ = "America/New_York")

#Authenticate Google Drive Access:
drive_auth()

directory = "~/GitHub/TEMPEST-1-porewater/data_do_not_commit/cdom"

getwd()
```

# Bring in the metadata:

### Set the study dates

```{r event and study dates}
endstudydate = lubridate::as_date("2024-01-31")
startstudydate = lubridate::as_date("2022-05-01")

year1_start = lubridate::as_date("2022-01-01")
year1_stop = lubridate::as_date("2022-12-31")

year2_start = lubridate::as_date("2023-01-01")
year2_stop = lubridate::as_date("2023-12-31")

year3_start = lubridate::as_date("2024-01-01")
year3_stop = lubridate::as_date("2024-12-31")

WaterDeliveryStart2022 = as.POSIXct("2022-06-22 05:30:00", tz = "EST")
WaterDeliveryStop2022 = as.POSIXct("2022-06-22 14:30:00", tz = "EST")

WaterDeliveryStart1 = as.POSIXct("2023-06-06 05:30:00", tz = "EST")
WaterDeliveryStop1 = as.POSIXct("2023-06-06 14:30:00", tz = "EST")

WaterDeliveryStart2 = as.POSIXct("2023-06-07 05:30:00", tz = "EST")
WaterDeliveryStop2 = as.POSIXct("2023-06-07 14:30:00", tz = "EST")
```

### Pull in TMP system level analysis (2022 event) 

```{r sys}

#If needed to create sample key: source("../tempest-system-level-analysis/scripts/02_tmp_doc_processing_2022Event.R")

sample_key <- readRDS("~/GitHub/tempest-system-level-analysis/data/for processing/TMP_Event_June2022_META_PW_SOURCE_DateTime.rds")

pwsite_key <- readxl::read_excel("~/GitHub/tempest-system-level-analysis/data/for processing/porewater_sites_complete_key.xlsx") %>%
  select(Plot, Grid) %>%
  unique()

inventory_directory <- "https://docs.google.com/spreadsheets/d/1sFWq-WKhemPzbOFInqhCu_Lx0lsO6a_Z/edit#gid=496164093"

file_path = "~/GitHub/TEMPEST-1-porewater/data_do_not_commit/porewaterinventory.xlsx"

drive_download(inventory_directory, path= file_path, overwrite = TRUE)

non_event_sample_key <- readxl::read_excel("~/GitHub/TEMPEST-1-porewater/data_do_not_commit/porewaterinventory.xlsx", skip=3, sheet="Individual") %>%
  select(Sample_ID, Evacuation_date_YYYMMDD, Collection_Date_YYYYMMDD, Collection_End_Time_24hrs, EST_EDT) %>%
  filter(str_detect(Sample_ID, "DOC/CDOM|DOC")) %>%
  rename(sample_name = Sample_ID,
         evacuation_date = Evacuation_date_YYYMMDD,
         collection_date = Collection_Date_YYYYMMDD,
         time = Collection_End_Time_24hrs,
         tz = EST_EDT) %>%
  mutate(evacuation_date = lubridate::as_date(as.character(evacuation_date), format = "%Y%m%d"),
         collection_date = lubridate::as_date(as.character(collection_date), format = "%Y%m%d"),
         elapsed_time = lubridate::days(collection_date - evacuation_date)) %>%
  select(sample_name, evacuation_date, collection_date, time, tz, elapsed_time)
  
```

### TEMPEST 1 sampling key 

```{r TEMPEST 1 sample key}
## add into here time points for pre and post sampling for gapfilling purposes later on
estuary_key1 = tibble(Plot = "ESTUARY",
                     Timepoint = "HR4", 
                     date = "20220622", 
                     time= "110000")

estuary_key2 = tibble(Plot = "ESTUARY",
                     Timepoint = "HR7", 
                     date = "20220622", 
                     time= "150000")

sample_key_merging <- sample_key %>%
  mutate(date = stringr::str_remove_all(Date, "-")) %>%
  rename(time = Start_time) %>%
  mutate(time = str_replace_all(time, ":", "")) %>%
  select(Plot,Timepoint, date, time) %>%
  bind_rows(estuary_key1,estuary_key2) %>%
  mutate(time = str_replace(time, "^[0-9]{5}$", function(x) paste0("0",x)))

non_event_sample_key_merging <- non_event_sample_key %>%
  mutate(Plot = stringr::str_extract(sample_name, 'FW|SW|C|ESTUARY'), 
         Grid = stringr::str_extract(sample_name, "B4|C3|C6|D5|E3|F4|F6|H3|H6|I5|SOURCE|ESTUARY|POOL|WELL"),
         date = stringr::str_extract(sample_name, "[0-9]{8}"),
         time = str_replace(time, "^[0-9]{3}$", function(x) paste0("0", x, "00")),
         time = str_replace(time, "^[0-9]{4}$", function(x) paste0(x, "00"))
         ) %>%
  select(Plot, Grid, date, time, tz, evacuation_date, collection_date) 
```

### Pooled sample sampling key 
```{r pooled} 


pooled_sample_key<- readxl::read_excel(file_path, skip=4, sheet="Pooled") %>%
  select(Sample_ID, Evacuation_date_YYYMMDD, Collection_Date_YYYYMMDD) %>%
  mutate(Plot = stringr::str_extract(Sample_ID, 'FW|SW|C'),
         Grid = "POOL") %>%
  rename(evacuation_date = Evacuation_date_YYYMMDD,
         collection_date = Collection_Date_YYYYMMDD) %>%
  mutate(evacuation_date = lubridate::as_date(as.character(evacuation_date), format = "%Y%m%d"),
         collection_date = lubridate::as_date(as.character(collection_date), format = "%Y%m%d"),
         date = stringr::str_extract(Sample_ID, "[0-9]{8}")) %>%
  mutate(date = lubridate::as_date(date, format = "%Y%m%d")) %>%
  group_by(date) %>%
  fill(evacuation_date, collection_date) %>%
  #Empty dates for the event dates, those are when collection and evacuation are usually the same date: 
  mutate(collection_date = case_when(is.na(collection_date) ~ date,
                                     TRUE ~ collection_date),
         evacuation_date = case_when(is.na(evacuation_date) ~ date,
                                     TRUE ~ evacuation_date),
         #some dates are wrong in the sample ID, so get them from the collection date column:
         date = case_when(is.na(date) ~ collection_date,
                          TRUE ~ date)) %>%
  select(Sample_ID, Plot, Grid, date, evacuation_date, collection_date) %>%
  mutate(date = as.character(date)) %>%
  ungroup()

sample_key_merging_all <-   non_event_sample_key_merging %>%
  bind_rows(pooled_sample_key) %>%
  select(-Sample_ID) %>%
  mutate(date = lubridate::as_date(date))
```
# 2. Functions -----------------------------------------------------------------

## Create a function to read in data
```{r functions}
read_eems <- function(data){
  #  read in data
  read.csv(file = data) %>% 
    rename(sample_id = Sample_ID,
           sample_description = Sample_Description) 
  #%>%
   # select(-sample_description)
  }

read_ids <- function(readme){
  # read in Read Me
  readxl::read_excel(path = readme, sheet = 1) %>% 
    rename(sample_id = Sample_ID,
           sample_description = Sample_Description) %>% 
    select(sample_name, sample_id, Action)
}
#Diluted samples have already been accounted for in the matlab script, so these corrections have been already applied.
```

# 3. Import data ---------------------------------------------------------------

```{r import}
## Create a list of files to download
files_eems <- list.files(path = directory, pattern = "SpectralIndices", full.names = TRUE) 
files_eems

files_abs <- list.files(path = directory, pattern = "RSU", full.names = TRUE) 
files_abs

#ReadMes <- list.files(path = directory, pattern = "key", full.names = TRUE) 

## Read in data, filter to TMP samples, and add sample name, add readme actions
eems <- files_eems %>% 
  map_df(read_eems) %>% 
  filter(grepl("TMP", sample_id)) %>% # filter to TMP samples only
  filter(!grepl("Ionic_Strength", sample_description)) %>% #filter out the ionic strength stuff
  select(-sample_description) %>%
  mutate(sample_id = str_trim(sample_id, side = c("both", "left", "right"))) %>% #Get rid of those stupid white spaces!!!!!!!
  select(-SUVA254) %>% #don't have proper SUVA calculations done in Matlab, so filter this out...
  mutate(across(everything(),  ~ case_when(.x >=0 ~ .x))) %>% #turn negatives into NAs
 select(-Sample_shorthand) %>%
   bind_rows()

abs <- files_abs %>% 
  map_df(read_eems) %>% 
  filter(grepl("TMP", sample_id)) %>% # filter to TMP samples only
  filter(!grepl("Ionic_Strength", sample_description)) %>% #filter out the ionic strength stuff
  select(-sample_description) %>%
  mutate(sample_id = str_trim(sample_id, side = c("both", "left", "right"))) %>% #Get rid of those stupid white spaces!!!!!!!
  mutate(across(everything(),  ~ case_when(.x >=0 ~ .x))) %>% #turn negatives into NAs
  bind_rows()
```

# 4. Merge data & metadata ---------------------------------------------------------------

```{r step 4}

# eems_all = full_join(eems, key, by = "sample_id") %>%
#   dplyr::filter(is.na(Action)) %>%
#   select(-Action, -sample_id) 

eems_all_meta =  eems %>% 
  left_join(abs, by= "sample_id") %>%
  rename(sample_name = sample_id) %>%
  mutate(sample_name = stringr::str_replace(sample_name,"POOLED","POOL")) %>%
  mutate(sample_name = stringr::str_replace(sample_name,"Pooled","POOL")) %>%
  mutate(sample_name = stringr::str_replace(sample_name, "PreW", "T0")) %>%
  mutate(sample_name = stringr::str_remove(sample_name,"_CDOM")) %>%
  dplyr::mutate(Event = stringr::str_extract(sample_name, "TMP"),
       Plot = stringr::str_extract(sample_name, 'FW|SW|C|ESTUARY'), 
       Grid = stringr::str_extract(sample_name, "B4|C3|C6|D5|E3|F4|F6|H3|H6|I5|SOURCE|BARGE|POOL|WELL"),
       Timepoint = stringr::str_extract(sample_name,"T[0-9]|HR[0-9]"),
       Timepoint = case_when(Timepoint == "HR8" ~ "HR7", #change the estuary HR8 to HR7
                             TRUE ~ Timepoint)) 
  



#Identify if any duplicates were run, this should return an empty data frame if not:#

duplicates <- eems_all_meta %>% subset(duplicated(sample_name))

duplicates

# there are some replicates: 
reps <- eems_all_meta %>%
  group_by(sample_name) %>%
  filter(n() > 1) 

reps

reps_names <- reps %>%
  select(sample_name) %>%
  unique() 

eems_all_meta_no_reps <- eems_all_meta %>%
  filter(!sample_name %in% reps_names$sample_name)

#need to remove a rep if the following conditions are met:
# 1) Flag says "high blank" &
# 2) Values are > 25% apart 
# If second condition is met but the first is not met, need to flag with "Inconsistent reps"
# If they are close in value, regardless of condition for 1), can be confident that they look good. 

reps_clean <- reps %>%
  group_by(sample_name) %>%
  mutate(across(S275_295:FDOM_RSU, 
                list(max = max, min = min, percerr = ~ (max(.) - min(.)) / max(.), 
                     Keep = ~ case_when((max(.) - min(.)) / max(.) < .25 ~ TRUE, TRUE ~ NA)), 
                .names = "{.col}_{.fn}")) %>% # these are all within 25% so merge
  select(S275_295:Timepoint) %>%
  summarise(across(S275_295:FDOM_RSU, 
                   ~ mean(., na.rm = TRUE)),
            across(everything(), first, .names = "{.col}")) 
```
# 7. Clean data ----------------------------------------------------------------

Need to get this metadata in check...
```{r step 7}

eems_all_meta_dups_merged <- eems_all_meta_no_reps %>% 
  bind_rows(reps_clean) %>%
  mutate(sample_name = case_when(sample_name == "TMP_FW_I5_202306627" ~ "TMP_FW_I5_20230627",
                                 TRUE ~ sample_name)) %>%
  left_join(sample_key_merging, by = c("Plot","Timepoint")) %>%
  mutate(date= case_when(is.na(date) ~ stringr::str_extract(sample_name, "[0-9]{8}"),
                         TRUE ~ date )) %>%
  mutate(date = lubridate::as_date(date)) %>%
  left_join(sample_key_merging_all, by= c("Plot","Grid","date"), suffix = c("", ".fill")) %>%
  mutate(time = coalesce(time, time.fill)) %>%
  select(-time.fill) %>%
  mutate(time = case_when(is.na(time) ~ stringr::str_extract(sample_name, "(?<=[0-9]{8}_)\\d{4}"),
                          TRUE ~ time),
         time = str_replace(time, '\\d+', function(m) str_pad(m, 6, pad = '0', side = ("right")))
  ) %>%
  mutate(time = case_when(is.na(time) ~ "115900", 
                          TRUE ~ time)) %>% #if no time recorded in the metadata sheet, fill in with noon
  mutate(Timepoint = case_when(is.na(Timepoint) & date == "2022-07-18" ~ "T5",
                               is.na(Timepoint) & date == "2022-07-21" ~ "T5",
                               is.na(Timepoint) & date == "2022-06-15" ~ "T0",
                               is.na(Timepoint) & date == "2022-06-13" ~ "T0",
                               TRUE ~ Timepoint)) %>%
  mutate(date = lubridate::as_date(date, format = "%Y%m%d"),
         time= strptime(time, format ="%H%M%S"),
         time = strftime(time, "%H:%M:%S"))  %>%
  mutate(Plot = case_when(Plot == "SW" & str_detect(sample_name, "ESTUARY") ~ "ESTUARY",
                          TRUE ~ Plot)) %>%
  mutate(plot = case_when(Plot == "FW" ~ "Freshwater",
                          Plot == "C" ~ "Control",
                          Plot == "SW" ~ "Estuarine-water",
                          Plot == "ESTUARY" ~ "Estuary water",
                          TRUE ~ Plot))   %>%
  mutate(Grid = case_when(is.na(Grid) & Plot == "ESTUARY" ~ "BARGE",
         TRUE ~ Grid)) %>%
  mutate(datetime = as.POSIXct(paste(date, time), format = "%Y-%m-%d %H:%M:%S"))   %>%
   rename(grid = Grid,
         collection_datetime = datetime) %>%
  #manual entry of missing evacuation information from the notes/inventory sheet: 
  mutate(evacuation_date = case_when(
    is.na(evacuation_date) & str_detect(collection_datetime, "2022-06-20") ~ as.Date("2022-06-18"),
    is.na(evacuation_date) & str_detect(collection_datetime, "2022-06-22") ~ as.Date("2022-06-22"),
    is.na(evacuation_date) & str_detect(collection_datetime, "2022-06-23") ~ as.Date("2022-06-22"),
    is.na(evacuation_date) & str_detect(collection_datetime, "2022-06-24") ~ as.Date("2022-06-23"),
    is.na(evacuation_date) & str_detect(collection_datetime, "2022-09-09") ~ as.Date("2022-09-09"),
    is.na(evacuation_date) & str_detect(collection_datetime, "2023-06-06") ~ as.Date("2023-06-05"),
    is.na(evacuation_date) & str_detect(collection_datetime, "2023-06-07 08:00:00") ~ as.Date("2023-06-06"),
     is.na(evacuation_date) & str_detect(collection_datetime, "2023-06-07") ~ as.Date("2023-06-07"),
    is.na(evacuation_date) & str_detect(collection_datetime, "2023-06-12") ~ as.Date("2023-06-08"),
    is.na(evacuation_date) & str_detect(collection_datetime, "2023-06-27") ~ as.Date("2023-06-23"),
    is.na(evacuation_date) & str_detect(collection_datetime, "2023-06-28") ~ as.Date("2023-06-23"),
     is.na(evacuation_date) & str_detect(collection_datetime, "2023-07-07") ~ as.Date("2023-07-05"),
    TRUE ~ evacuation_date)) %>%
  filter(collection_datetime != "2022-05-23 11:59:00") %>%
  mutate(set_tz = with_tz(collection_datetime, tzone = "America/New_York"),
         is_dst = dst(set_tz),
    tz = case_when(is.na(tz) &  is_dst == TRUE ~ "EDT",
                   is.na(tz) &  is_dst != TRUE ~ "EST",
                   TRUE ~ tz)) %>%
  select(-set_tz, -is_dst) %>%
  select(Event, plot, grid, collection_datetime, sample_name, S275_295:FDOM_RSU, evacuation_date)

```

Now, split out the source and the porewater...

```{r make final data frames}
source_eems_all <- eems_all_meta_dups_merged %>%
  filter(grepl("SOURCE|ESTUARY|BARGE", sample_name)) 

knitr::kable(source_eems_all) %>% kableExtra::kable_styling("striped", full_width = F) %>%
  kableExtra::scroll_box(width = "100%", height = "200px")

PW_eems_grids <- eems_all_meta_dups_merged %>%
  filter(grid != "SOURCE") %>%
  filter(grid != "WELL") %>%
  filter(grid != "BARGE") %>%
  filter(grid != "POOL")

knitr::kable(PW_eems_grids) %>% kableExtra::kable_styling("striped", full_width = F) %>%
  kableExtra::scroll_box(width = "100%", height = "200px")

PW_eems_all_pooled_only <- eems_all_meta_dups_merged %>%
  filter(grid != "SOURCE") %>%
  filter(grid != "WELL") %>%
  filter(grid != "BARGE") %>%
  filter(grid == "POOL")

knitr::kable(PW_eems_all_pooled_only) %>% kableExtra::kable_styling("striped", full_width = F) %>%
  kableExtra::scroll_box(width = "100%", height = "200px")

PW_eems_allwpooled <- eems_all_meta_dups_merged %>%
  filter(grid != "SOURCE") %>%
  filter(grid != "WELL") %>%
  filter(grid != "BARGE")

knitr::kable(PW_eems_allwpooled) %>% kableExtra::kable_styling("striped", full_width = F) %>%
  kableExtra::scroll_box(width = "100%", height = "200px")
```

# Save data

make eval=FALSE if you are not writing the version of record of these files: 

## Save for manuscript

```{r manuscript saving, eval=FALSE}
saveRDS(source_eems_all, "~/GitHub/TEMPEST-1-porewater/processed data/TMP_SOURCE_CDOM_L1_TMP1TMP2.rds")

saveRDS(PW_eems_all_pooled_only, "~/GitHub/TEMPEST-1-porewater/processed data/TMP_PW_POOLED_CDOM_L1_TMP1TMP2.rds")

saveRDS(PW_eems_grids, "~/GitHub/TEMPEST-1-porewater/processed data/TMP_PW_grids_CDOM_L1_TMP1TMP2.rds")
```

## Write for Google Drive L1

```{r l1 data}

l1_porewatergrids_2022 = PW_eems_allwpooled  %>%
   filter(collection_datetime < year1_stop & collection_datetime > year1_start)
#2022 L1
knitr::kable(l1_porewatergrids_2022) %>% kableExtra::kable_styling("striped", full_width = F) %>%
  kableExtra::scroll_box(width = "100%", height = "200px")

l1_porewatergrids_2023 = PW_eems_allwpooled  %>%
   filter(collection_datetime < year2_stop & collection_datetime > year2_start)

#2023 L1
knitr::kable(l1_porewatergrids_2023) %>% kableExtra::kable_styling("striped", full_width = F) %>%
  kableExtra::scroll_box(width = "100%", height = "200px")

```

```{r write L1, eval=FALSE}

write_csv(l1_porewatergrids_2022, "~/GitHub/TEMPEST-1-porewater/processed data/for_google_drive/TMP_PW_GRIDSandPOOL_CDOM_Indicies_L1_2022.csv")

write_csv(l1_porewatergrids_2023, "~/GitHub/TEMPEST-1-porewater/processed data/for_google_drive/TMP_PW_GRIDSandPOOL_CDOM_Indicies_L1_2023.csv")

```


  
  
  