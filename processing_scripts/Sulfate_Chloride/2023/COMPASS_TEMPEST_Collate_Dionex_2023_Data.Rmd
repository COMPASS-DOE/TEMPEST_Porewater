---
title: "COMPASS_TEMPEST_Collate_Dionex_2023_Data"
author: "Stephanie J. Wilson"
date: "2025-08-29"
output: html_document
---

```{r}
Sample_Year = "2023"
Run_notes = "Some sample IDs are missing from metadata: 
TMP_SW_H6_20230612
TMP_FW_F6_20230606
TMP_SW_E5_20230606
TMP_SW_F6_202311
TMP_SW_B4_202311
TMP_SW_H6_202311
TMP_AQUIFER_SAMPLE_A
TMP_AQUIFER_SAMPLE_B
TMP_AQUIFER_SAMPLE_C"
```

```{r setup, include=FALSE}

#Packages that are required 
lapply(c(
  "dplyr", "ggplot2", "ggpubr", "stringr",
  "purrr", "tidyverse", "here", "broom", "tibble",
  "googledrive", "googlesheets4", "data.table", 
  "matrixStats", "gridExtra", "grid", "readxl"), 
  library, character.only = TRUE)

#Packages for loading metadata
require(pacman)
pacman::p_load(janitor, # useful for simplifying column names
               googlesheets4, # read_sheet 
               googledrive, # drive_ functions
               plotrix,
               here) 

common_tz = "Etc/GMT+5"

Sys.setenv(TZ = "America/New_York")
```

#Read in and collate all the files in the Processed Data folder 
```{r}

files <- list.files(path = "Processed Data", pattern = "\\.csv$", full.names = TRUE)

# 3. Read and combine all CSVs
all_data <- files %>%
  lapply(read.csv, colClasses = "character") %>%    # or read.csv if you prefer base R
  bind_rows()             # combine into one data frame

all_data <- all_data[, -which(names(all_data) == "X")]

#remove duplicates from the sample dataframe bc we are just taking the first dup run
all_data <- all_data %>%
  filter(!str_detect(Sample_ID, "spk"))

colnames(all_data)

##Add Time of Day column (AM < 1200, PM > 1200)
all_data$Time <- as.numeric(all_data$Time)
##Change "Source" to "Sourcewater" 
all_data$Grid <- replace(all_data$Grid, all_data$Grid == "SOURCE", "SOURCEWATER")

##For 20230607, need to change times to AM or PM in Sample ID
all_data1 <- all_data %>% 
  mutate(
    Project = "TMP", 
    Time_of_day = ifelse(Time<1200, "AM", "PM"), 
    Sample_ID = paste(Project, Plot, Grid, Date, Time_of_day, sep = "_")
  )

all_data1$Sample_ID <- gsub("_NA", "", all_data1$Sample_ID)
all_data_nsw <- subset(all_data1, Grid != "SOURCEWATER")

##For Sourcewater samples, need to code source samples as T1-3 based on earliest to latest times
all_data_sw <- subset(all_data1, Grid == "SOURCEWATER")

all_data_sw <- all_data_sw %>% 
  group_by(Plot, Date) %>% 
  arrange(Time, .by_group = TRUE) %>% # Sort by Time ascending
  mutate(Event_Time = paste0("T", row_number())) %>% 
  ungroup()
  
all_data_sw <- all_data_sw %>% 
  mutate(
    Sample_ID = paste(Project, Plot, Grid, Date, Event_Time, sep = "_")
  )

all_data2 <- bind_rows(all_data_sw, all_data_nsw)

colnames(all_data2)

all_data3 <- all_data2 %>% 
  select("Sample_ID", "SO4_ppm", "SO4_Area", "Cl_ppm", "Cl_Area", "SO4_mM", "Cl_mM", "salinity", "Time")

```

## Pull in active porewater tracking inventory sheet from Google Drive: 
```{r rest of metadata, include=FALSE}

#Run these to pull the TEMPEST porewater metadata into GitHub if not already there
# inventory_directory <- "https://docs.google.com/spreadsheets/d/1sFWq-WKhemPzbOFInqhCu_Lx0lsO6a_Z/edit#gid=496164093"
# 
# drive_download(inventory_directory, overwrite = TRUE)
# 
# sheet_names <- excel_sheets("TEMPEST_PorewaterInventory_May2022_Present.xlsx")
# sheet_names

raw_metadata_lys <- read_excel("TEMPEST_PorewaterInventory_May2022_Present.xlsx", sheet = "Porewater - Individual", skip = 3)

raw_metadata_sw <- read_excel("TEMPEST_PorewaterInventory_May2022_Present.xlsx", sheet = "Source Water", skip = 3)


```


##Create similar sample IDs to match with run samples 
```{r pull in metadata for later, include=FALSE}

###LYSIMETER SAMPLES###
#select SO4/Cl samples 
raw_metadata_lys <- subset(raw_metadata_lys, Analyte == "SO4/Cl/H2S")

#select 2023 samples
raw_metadata_lys_year <- raw_metadata_lys %>%  
  filter(str_detect(Sample_ID, Sample_Year))

#separate samples into columns
raw_metadata_lys_year <- raw_metadata_lys_year %>%
  separate(
    col = Sample_ID,
    sep = "_",
    into = c("Project", "Zone", "Source" ,"Grid", "Depth", "Analyte", "Collection_Date", "Time_of_day"),
    remove = FALSE)

#create IDs from what was collected for comparison later
raw_metadata_lys_ids <- raw_metadata_lys_year %>%
  mutate(Cl_SO4_ID = paste(Project,
                          Zone,
                          Grid,
                          Collection_Date_YYYYMMDD, 
                          Time_of_day, 
                          sep = "_"))

raw_metadata_lys_ids$Cl_SO4_ID <- gsub("_NA", "", raw_metadata_lys_ids$Cl_SO4_ID)


###SOURCEWATER SAMPLES###
#select SO4/Cl samples 
raw_metadata_sw <- raw_metadata_sw %>%  
  filter(str_detect(Sample_ID, "SO4"))

#select 2023 samples
raw_metadata_sw_year <- raw_metadata_sw %>%  
  filter(str_detect(Sample_ID, Sample_Year))

#separate samples into columns
raw_metadata_sw_sw <- raw_metadata_sw_year %>%
  separate(
    col = Sample_ID,
    sep = "_",
    into = c("Project", "Source", "Zone", "Event_Time", "Analyte", "Collection_Date", "Time_of_day"),
    remove = FALSE)

#change "Source" to "Sourcewater" 
raw_metadata_sw_sw$Source <- replace(raw_metadata_sw_sw$Source, raw_metadata_sw_sw$Source == "Source", "SourceWater")

#create IDs from what was collected for comparison later
raw_metadata_sw_combined <- raw_metadata_sw_sw %>%
  mutate(Cl_SO4_ID = paste(Project,
                          Zone,
                          Source, 
                          Collection_Date, 
                          Event_Time, 
                          sep = "_")) %>%
  rename("Notes" = "Notes:")



#combine porewater and sourcewater samples
dionex_metadata <- bind_rows(raw_metadata_lys_ids, raw_metadata_sw_combined)

#remove old ID's
dionex_metadata$Sample_ID <- NULL

colnames(dionex_metadata)

# head(dionex_metadata)

```


## Check to see if samples run match metadata & merge info
```{r check sample ids with metadata, echo=FALSE, warning = FALSE}

#check to see if all samples are present in the metadata 
all_data3$Sample_ID <- toupper(all_data3$Sample_ID)
dionex_metadata$Cl_SO4_ID <- toupper(dionex_metadata$Cl_SO4_ID)

all_present <- all(all_data3$Sample_ID %in% dionex_metadata$Cl_SO4_ID)

if (all_present) {
  message("All sample IDs are present in metadata.")
} else {
  message("Some sample IDs are missing from metadata.")
  
  # Optional: Which ones are missing?
  missing_ids <- setdiff(all_data3$Sample_ID, dionex_metadata$Cl_SO4_ID)
  print(missing_ids)
}


#merge metadata with sample run data 
merged_data <- all_data3 %>%
  left_join(dionex_metadata, by = c("Sample_ID" = "Cl_SO4_ID"))

merged_data$Plot <- str_replace_all(merged_data$Plot, "Contol", "Control")

merged_data$Sample_ID <- paste(merged_data$Sample_ID, merged_data$Depth, sep = "_")
merged_data$Sample_ID <- gsub("_NA", "", merged_data$Sample_ID)

```

## Visualize Data by Plot   
```{r Visualize Data, echo=FALSE, warning=FALSE}

#Plot samples to get a first look at concentrations (sanity check)
data_plotting <- merged_data %>%
  subset(!is.na(Plot))

#Order by Zone from Upland to Surface Water
unique(data_plotting$Plot)
data_plotting$Plot = factor(data_plotting$Plot, levels = c("Control", "Freshwater", "Saltwater"))
data_plotting <- data_plotting[order(data_plotting$Plot), ]

data_plotting$SO4_ppm <- as.numeric(data_plotting$SO4_ppm)
data_plotting$Cl_ppm <- as.numeric(data_plotting$Cl_ppm)

#group the data for plotting
data_plotting <- data_plotting %>%
  mutate(row_num = factor(row_number())) %>%  # create row_num as factor per group
  ungroup()

#Plot data and change colors based on Zone:
viz_cl_plot <- ggplot(data_plotting, aes(x = row_num, y = Cl_ppm, fill = Plot)) +
  geom_bar(stat = "identity", position = position_dodge2(preserve = "single")) +
  facet_wrap(~ Plot, scales="free") +
  scale_fill_manual(values = c(
    "Control" = "springgreen2",
    "Freshwater" = "cyan2",
    "Saltwater" = "violetred2"
  )) +
  theme_classic() +
  theme(axis.text.x = element_blank()) +
  labs(x = " ", y = "Cl (mg/L)", title = "Samples: Chloride") +
  scale_x_discrete(drop = TRUE)


viz_so4_plot <-  ggplot(data_plotting, aes(x = row_num, y = SO4_ppm, fill = Plot)) +
  geom_bar(stat = "identity", position = position_dodge2(preserve = "single")) +
  facet_wrap(~ Plot, scales="free") +
  scale_fill_manual(values = c(
    "Control" = "springgreen2",
    "Freshwater" = "cyan2",
    "Saltwater" = "violetred2"
  )) +
  theme_classic() +
  theme(axis.text.x = element_blank()) +
  labs(x = " ", y = "SO4 (mg/L)", title = "Samples: SO4") +
  scale_x_discrete(drop = TRUE)

ggarrange(viz_cl_plot, viz_so4_plot, nrow=2, ncol=1)


```

## Write the 2023 file out to the folder 
```{r, echo=FALSE}
colnames(merged_data)

final_data <- merged_data %>%
  mutate(
    Depth_cm = Depth, 
    SO4_Conc_flag = NA, 
    SO4_QAQC_flag = NA, 
    Cl_Conc_flag = NA, 
    Cl_QAQC_flag = NA, 
    Analysis_rundate = NA, 
    Run_notes = NA, 
    Field_notes = Notes
  ) %>%
  rename(
    SO4_Conc_mM = SO4_mM, 
    Cl_Conc_mM = Cl_mM
  ) %>%
  select(
         Project, Zone, Grid, Depth_cm, Event_Time, Time_of_day, Source, 
         Volume_mL, Collection_Date, Sample_ID, 
         SO4_ppm, SO4_Conc_mM, SO4_Conc_flag, SO4_QAQC_flag, Cl_ppm, Cl_Conc_mM, Cl_Conc_flag, Cl_QAQC_flag, salinity,
         Analysis_rundate,  Run_notes, Field_notes
        # list columns in the order you want them
  )

write.csv(final_data, "COMPASS_TEMPEST_SO4_Cl_2023.csv")

```

