---
title: "TMP Porewater DOC for Manuscript"
author: "AMP"
date: "`r Sys.Date()`"
output: html_document
---

# NOTE THIS SCRIPT IS ONLY GOOD FOR TMP 1 & TMP 2 up to TMP 3. 
# DO NOT USE THIS SCRIPT FOR TMP 3 and BEYOND

The script has not yet been validated to work beyond YR end of TMP 2. 

***Note: Date times break for an unknown reason even after setting the system time in the setup IF your computer time is NOT on eastern timezone. so, you need to change that if you're not living in eastern time on your computer to prevent this unknown issue from really messing with the data.*** 

This script imports raw data for NPOC and TDN measured using a Shimadzu TOC-L at PNNL MCRL and exports clean, Level 1 QC'ed data. Raw Data are read in from L0 folder on Google Drive. 

Created: 2022-01-15 by Peter Regier for EXCHANGE
Updated: 2022-06-26 by Allison Myers-Pigg for TEMPEST
Updated and adapted for markdown: 2024-02-10 by Allison Myers-Pigg for TEMPEST 2.0


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, 
                      message = F,
                      warning = F)

# load packages
require(pacman)
pacman::p_load(tidyverse, # keep things tidy
               janitor, # useful for simplifying column names
               googlesheets4, # read_sheet 
               googledrive, # drive_ functions
               plotrix,
               here) 

common_tz = "Etc/GMT+5"

Sys.setenv(TZ = "America/New_York")

getwd()
```

## Pull in TMP system level analysis (2022 event) 

```{r sys}
## Set Github filepath for NPOC raw data files:

#If needed: source("../tempest-system-level-analysis/scripts/02_tmp_doc_processing_2022Event.R")

sample_key <- readRDS("~/GitHub/tempest-system-level-analysis/data/for processing/TMP_Event_June2022_META_PW_SOURCE_DateTime.rds")

pwsite_key <- readxl::read_excel("~/GitHub/tempest-system-level-analysis/data/for processing/porewater_sites_complete_key.xlsx") %>%
  select(Plot, Grid) %>%
  unique()

inventory_directory <- "https://docs.google.com/spreadsheets/d/1sFWq-WKhemPzbOFInqhCu_Lx0lsO6a_Z/edit#gid=496164093"

drive_download(inventory_directory, path="~/GitHub/TEMPEST-1-porewater/data_do_not_commit/porewaterinventory.xlsx", overwrite = TRUE)

non_event_sample_key <- readxl::read_excel("~/GitHub/TEMPEST-1-porewater/data_do_not_commit/porewaterinventory.xlsx", skip=3, sheet="Individual") %>%
  select(Sample_ID, Evacuation_date_YYYMMDD, Collection_Date_YYYYMMDD, Collection_End_Time_24hrs, EST_EDT) %>%
  filter(str_detect(Sample_ID, "DOC")) %>%
  rename(sample_name = Sample_ID,
         evacuation_date = Evacuation_date_YYYMMDD,
         collection_date = Collection_Date_YYYYMMDD,
         time = Collection_End_Time_24hrs,
         tz = EST_EDT) %>%
  mutate(evacuation_date = lubridate::as_date(as.character(evacuation_date), format = "%Y%m%d"),
         collection_date = lubridate::as_date(as.character(collection_date), format = "%Y%m%d"),
         elapsed_time = lubridate::days(collection_date - evacuation_date)) %>%
  select(sample_name, evacuation_date, collection_date, time, tz, elapsed_time)
  
```

```{r TEMPEST 1 sample key}
## add into here time points for pre and post sampling for gapfilling purposes later on
estuary_key1 = tibble(Plot = "ESTUARY",
                     Timepoint = "HR4", 
                     date = "20220622", 
                     time= "110000")

estuary_key2 = tibble(Plot = "ESTUARY",
                     Timepoint = "HR7", 
                     date = "20220622", 
                     time= "150000")

sample_key_merging <- sample_key %>%
  mutate(date = stringr::str_remove_all(Date, "-")) %>%
  rename(time = Start_time) %>%
  mutate(time = str_replace_all(time, ":", "")) %>%
  select(Plot,Timepoint, date, time) %>%
  bind_rows(estuary_key1,estuary_key2) %>%
  mutate(time = str_replace(time, "^[0-9]{5}$", function(x) paste0("0",x)))

non_event_sample_key_merging <- non_event_sample_key %>%
  mutate(Plot = stringr::str_extract(sample_name, 'FW|SW|C|ESTUARY'), 
         Grid = stringr::str_extract(sample_name, "B4|C3|C6|D5|E3|F4|F6|H3|H6|I5|SOURCE|ESTUARY|POOL|WELL"),
         date = stringr::str_extract(sample_name, "[0-9]{8}"),
         time = str_replace(time, "^[0-9]{3}$", function(x) paste0("0", x, "00")),
         time = str_replace(time, "^[0-9]{4}$", function(x) paste0(x, "00"))
         ) %>%
  select(Plot, Grid, date, time, tz, evacuation_date, collection_date) 
```


<!-- {r read in and save files from google drive} -->

<!-- raw_data_path <- "./data_do_not_commit/doc_L0_fromdrive/" -->

<!--  l0_file_list <- drive_ls("https://drive.google.com/drive/folders/1P65nP0CFY8V1iEY47O_fnNhvNS6D6eNt") -->

<!--  currently having issues getting this to work going to use the data already on github for this for now -->

<!-- {r Pull L0 data from Gdrive, eval = F} -->
<!--   # Only use this chunk if you've not saved the data into github previously, pull from drive -->
<!--   # pulled down the data I want, and it takes a while to run since the files are big -->

<!-- drive_download_ <- function(data){ -->
<!--   message(paste("Downloading", data$name)) -->
<!--   # you could add an ifelse to only download files it doesn't fine in raw_data_path -->
<!-- drive_download( -->
<!-- as_id(data$id), overwrite = T, path = paste0(raw_data_path, data$name)) -->
<!-- } -->

<!--  # Use a for-loop to read in files in a way that I can see what's going on -->
<!--  # Download data to local. I tried to map() but for some reasons it doesn't work? -->

<!-- for(i in 1:nrow(l0_file_list)){ -->
<!--    drive_download_(l0_file_list %>% slice(i)) -->
<!--  }  -->
 

## Set Github filepath for NPOC raw data files - this is temporary - in ideal world we would be doing the previous steps

```{r github directory}
directory= file.path(here() %>% dirname(), 'tempest-system-level-analysis/data/raw/DOC')

```

# Functions

```{r functions, include=FALSE}
## Create a function to read in data
read_data <- function(data){
  # First, scrape date from filename
  rundate <- str_extract(data, "[0-9]{8}")
  # Second, read in data
  read_delim(file = data, skip = 10, delim = "\t") %>% 
    rename(sample_name = `Sample Name`, 
           npoc_raw = `Result(NPOC)`, 
           tdn_raw = `Result(TN)`,
           run_datetime = `Date / Time`) %>% 
    select(sample_name, npoc_raw, tdn_raw,run_datetime) %>% 
    mutate(rundate = rundate)
}

read_mes <- function(readme){
  # First, scrape date from filename
  rundate <- str_extract(readme, "[0-9]{8}")
  # Second, read in Read Me
  readxl::read_excel(path = readme, sheet = 1) %>% 
    rename(sample_name = `Sample Name`,
           sample_vol = `Sample wt`,
           total_vol = `Total vol:`) %>% 
    select(sample_name, Action, sample_vol, total_vol) %>% 
    mutate(rundate = rundate)
}
```

# Review files 

```{r figure out files to use, include=TRUE}
files <- list.files(path = here::here(directory), pattern = "Summary", full.names = TRUE) 
ReadMes <- list.files(path = here::here(directory), pattern = "Readme", full.names = TRUE) 

files
```

### Set the study dates

```{r event and study dates}
endstudydate = lubridate::as_date("2024-01-31")
startstudydate = lubridate::as_date("2022-05-01")

year1_start = lubridate::as_date("2022-01-01")
year1_stop = lubridate::as_date("2022-12-31")

year2_start = lubridate::as_date("2023-01-01")
year2_stop = lubridate::as_date("2023-12-31")

year3_start = lubridate::as_date("2024-01-01")
year3_stop = lubridate::as_date("2024-12-31")

WaterDeliveryStart2022 = as.POSIXct("2022-06-22 05:30:00", tz = "EST")
WaterDeliveryStop2022 = as.POSIXct("2022-06-22 14:30:00", tz = "EST")

WaterDeliveryStart1 = as.POSIXct("2023-06-06 05:30:00", tz = "EST")
WaterDeliveryStop1 = as.POSIXct("2023-06-06 14:30:00", tz = "EST")

WaterDeliveryStart2 = as.POSIXct("2023-06-07 05:30:00", tz = "EST")
WaterDeliveryStop2 = as.POSIXct("2023-06-07 14:30:00", tz = "EST")
```

Include this if you are only wanting to run the script for certain dates 

<!-- Input your run dates of interest into the files_dates dataframe:  -->

<!-- ```{r set dates for analysis, include=TRUE} -->
<!-- #  -->
<!-- # #files_dates = c( -->
<!-- #                 "20220701", #2022  -->
<!-- #                 "20220708", -->
<!-- #                 "20220711", -->
<!-- #                 "20220715", -->
<!-- #                 "20220729", -->
<!-- #                 "20220803", -->
<!-- #                 "20220819", -->
<!-- #                 "20220922", -->
<!-- #                 "20221025", -->
<!-- #                 "20221209", -->
<!-- #                 "20230209", -->
<!-- #                 "20230512", -->
<!-- #                 "20230531", #2023 start -->
<!-- #                 "20230608", -->
<!-- #                 "20230609", -->
<!-- #                 "20230622", -->
<!-- #                 "20230706", -->
<!-- #                 "20230824", -->
<!-- #                 "20231010", -->
<!-- #                 "20231012", -->
<!-- #                 "20231115", -->
<!-- #                 "20231214") -->




<!-- ``` -->


# Import Data
```{r import data, include= TRUE, message=FALSE, warning=FALSE}

npoc_raw <- files %>% 
  map_df(read_data) %>% 
  filter(grepl("TMP", sample_name)) %>% # filter to TMP samples only
#  filter(rundate %in% files_dates) %>% # filter to just run dates you need 
  bind_rows() 

blanks_raw <- files %>% 
  map_df(read_data) %>% 
  filter(grepl("^Blank", sample_name)) %>% # filter to blanks only
#  filter(rundate %in% files_dates) %>% # filter to just run dates you need 
  bind_rows() 

readmes_dilution_action <- ReadMes %>% 
  map_df(read_mes) %>% 
  filter(grepl("TMP", sample_name)) %>% # filter to TMP samples only
  filter(grepl("ilution correction", Action)) %>%
#  filter(rundate %in% files_dates) %>% # filter to just run dates you need 
  bind_rows() 

readmes_all <- ReadMes %>% 
  map_df(read_mes) %>% 
  filter(grepl("TMP", sample_name)) %>% # filter to TMP samples only
#  filter(rundate %in% files_dates) %>% # filter to just run dates you need 
    mutate(Action = case_when(sample_name == "TMP_SW_F4_T3" ~ "Omit", # due to incorrect duplicate naming
                            sample_name == "TMP_ESTUARY_BARGE_HR8_DOC" & rundate == "20220629" ~ "Omit", #remove this weird sample that should have been flagged because its basically 0
                              TRUE ~ Action)) %>%
  bind_rows() 

curvepts <-files %>% 
  map_df(read_data) %>% 
  filter(grepl("ppm|std", sample_name, ignore.case = TRUE) & !grepl("CK", sample_name, ignore.case = TRUE)) %>% # filter to curves only
#  filter(rundate %in% files_dates) %>% # filter to just run dates you need 
  filter(!grepl("10/25/2022 7:24:33 PM|9/22/2022 9:03:23 PM", run_datetime)) %>% # filter out curve points you don't want
  rename(standard_high_C = npoc_raw,
         standard_high_N = tdn_raw) %>%
  select(rundate,standard_high_C,standard_high_N) %>%
  pivot_longer(cols = c(standard_high_C,standard_high_N)) %>%
  na.omit() %>%
  group_by(rundate) %>%
  distinct()%>%
  pivot_wider(names_from= name, values_from = value)%>%
  bind_rows() 
```

# Calculate blanks and add to data

```{r blanks}
blanks <- blanks_raw %>% 
  filter(!run_datetime %in% NA) %>% 
  mutate(npoc_raw = ifelse(npoc_raw > 0, npoc_raw, NA)) %>%
  mutate(tdn_raw = ifelse(tdn_raw > 0, tdn_raw, NA)) %>%
  group_by(rundate) %>% 
  summarize(npoc_blank= round(mean(npoc_raw[!is.na(npoc_raw)]), 2),
            npoc_blank_SD= round(sd(npoc_raw[!is.na(npoc_raw)]), 2), #add SD columns
            tdn_blank= round(mean(tdn_raw[!is.na(tdn_raw)]), 2),
            tdn_blank_SD= round(sd(tdn_raw[!is.na(tdn_raw)]), 2)) %>% #add SD columns
  select(rundate, npoc_blank, npoc_blank_SD, tdn_blank, tdn_blank_SD)

print(blanks) # Check out the blank data 
```

# Flag sketch data 

someday you should make this a function 

```{r flagging} 
npoc_flagged <- npoc_raw %>% 
  filter(grepl("TMP", sample_name)) %>% # filter to TMP samples only
  inner_join(blanks, by = "rundate") %>% 
  inner_join(curvepts, by= "rundate") %>%
  mutate(tdn_flag = case_when(tdn_raw > standard_high_N ~ "value above cal curve",
                              tdn_blank > 0.25*tdn_raw ~ "blank is ≥ 25% of sample value", # flagging if blank concentration is > 20% of the sample concentration 
                               sample_name == "TMP_SW_F4_T3" ~ "incorrect sample naming, cannot resolve"), 
         #most curves only to 50, those samples were not above it. making 100 for the August and September, which used 0-100
         npoc_flag = case_when(npoc_raw > standard_high_C ~ "value above cal curve",
                               npoc_blank > 0.25*npoc_raw ~ "blank is ≥ 25% of sample value", # flagging if blank concentration is > 20% of the sample concentration
                              sample_name == "TMP_SW_F4_T3" ~ "incorrect sample naming, cannot resolve"),
          npoc_raw = case_when(npoc_flag == "incorrect sample naming, cannot resolve" ~ NA,
                               TRUE ~ npoc_raw),
          tdn_raw = case_when(tdn_flag == "incorrect sample naming, cannot resolve" ~ NA,
                              TRUE ~ tdn_raw)
  )

print(npoc_flagged)
```

# Dilution Corrections & Flagging 


**someday you should make this a function** 

Some of the pooled samples are actually not pooled and only one lysimeter. These should be incorporated herein so if they are replicates of a DOC value from an individual lysimeter they are incorporated into the values, and then removed as a "Pooled" sample. 

```{r dilutions}
dilutions = 
  readmes_dilution_action %>% 
  mutate(Dilution =  total_vol/sample_vol) %>% 
  dplyr::select(rundate, sample_name, Action, Dilution) %>% 
  force()

samples_to_dilution_corrected = 
  npoc_flagged %>%
  left_join(dilutions, by = c("sample_name", "rundate")) %>% 
  filter(grepl("ilution correction", Action)) %>%
  filter(!Action %in% "Omit") %>% 
  filter(!Action %in% "omit") %>% 
  mutate(doc_mg_l= npoc_raw * Dilution, tdn_mg_l = tdn_raw * Dilution, # True concentration = diluted concentration * total vol / sample vol
         doc_mg_l = as.numeric(doc_mg_l), doc_mg_l = round(doc_mg_l, 2),
         tdn_mg_l= as.numeric(tdn_mg_l), tdn_mg_l= round(tdn_mg_l, 2)) %>%
  mutate(doc_mg_l = case_when(Dilution > 30 & npoc_flag == "blank is ≥ 25% of sample value" ~ NA,
                              TRUE ~ doc_mg_l), # removing values if high blanks and high dilution ratios, potentially large source of error. 
         npoc_flag = case_when(is.na(doc_mg_l) ~ "omitted for high dilution and blank values",
                               TRUE ~ npoc_flag),
         tdn_mg_l = case_when(Dilution > 30 & tdn_flag == "blank is ≥ 25% of sample value" ~ NA,
                              TRUE ~ tdn_mg_l),
         tdn_flag = case_when(is.na(tdn_mg_l) ~ "omitted for high dilution and blank values",
                              TRUE ~ tdn_flag)) # removing values if high blanks and high dilution ratios, potentially large source of error. 

all_samples_dilution_corrected =
  npoc_flagged %>%
  left_join(readmes_all, by = c("sample_name", "rundate")) %>% 
  mutate(doc_mg_l = npoc_raw, tdn_mg_l = tdn_raw) %>%
  filter(!grepl("ilution correction", Action)) %>% 
  filter(!Action %in% "Omit") %>%
  filter(!Action %in% "omit") %>% 
  bind_rows(samples_to_dilution_corrected) %>%
  dplyr::select(sample_name, rundate, doc_mg_l, tdn_mg_l, npoc_flag, tdn_flag)%>%
  mutate(doc_mg_l = if_else(doc_mg_l < 0, "NA", as.character(doc_mg_l)),
         tdn_mg_l = if_else(tdn_mg_l < 0, "NA", as.character(tdn_mg_l)),
         doc_mg_l = as.numeric(doc_mg_l), doc_mg_l = round(doc_mg_l, 2),
         tdn_mg_l= as.numeric(tdn_mg_l), tdn_mg_l= round(tdn_mg_l, 2))

#Identify if any duplicates were run, this should return an empty data frame if not:#

duplicates <- all_samples_dilution_corrected %>% subset(duplicated(sample_name))

print(duplicates)


#MANUALLY Fix sample names and see if there were multiple of the same sample split for some reason run:

 all_samples_dilution_corrected2 <- all_samples_dilution_corrected %>% 
   #2022 event naming was a hot mess: 
    mutate(sample_name = stringr::str_replace(sample_name,"HR6","HR7")) %>% #HR6 samples are mislabeled, should be HR7
    mutate(sample_name = stringr::str_replace(sample_name, "_DILUTED4mLsmpl3mLwater", "")) %>%
    mutate(sample_name = stringr::str_replace(sample_name, "_Diluted", "")) %>%
    mutate(sample_name = stringr::str_replace(sample_name, "_1of1", "")) %>%
    mutate(sample_name = stringr::str_replace(sample_name, "_1of2", "")) %>%
    mutate(sample_name = stringr::str_replace(sample_name, "_2of2", "")) %>%
    mutate(sample_name = stringr::str_replace(sample_name, "_1of3", "")) %>%
    mutate(sample_name = stringr::str_replace(sample_name, "_2of3", "")) %>%
    mutate(sample_name = stringr::str_replace(sample_name, "_3of3", "")) %>%
    mutate(sample_name = stringr::str_replace(sample_name, "PreW", "T0")) %>%
    mutate(sample_name = stringr::str_replace(sample_name, "TMP_C_F4_20221128", "TMP_C_F6_20221128")) %>% # nov/dec C F6 naming mix up with F4 in DOC run
      mutate(sample_name = case_when(sample_name == "TMP_FW_POOL_202310" ~ "TMP_FW_POOL_20231002", #this didn't have a date in the sample name
                              TRUE ~ sample_name)) %>%
   #Relevant Beyond the 2022 Event: 
    mutate(sample_name = stringr::str_remove(sample_name,"_DOC")) %>%
    mutate(sample_name = stringr::str_remove(sample_name,"_A$")) %>%
    mutate(sample_name = stringr::str_remove(sample_name, "_B$")) %>%
    mutate(sample_name = stringr::str_remove(sample_name,"_EXTRA")) %>%
    mutate(sample_name = stringr::str_replace(sample_name,"POOLED","POOL")) %>%
    mutate(sample_name = stringr::str_remove(sample_name,"_Subsample")) %>% ####WHAT ARE THESE???????####
   #These are the pooled samples that are not actually pooled:
    mutate(sample_name = stringr::str_replace(sample_name, "TMP_C_POOL_T2", "TMP_C_H6_T2"))
      # control pooled T2 is actually not a pooled sample - field metadata sheets have that sample coming from one grid: H6
 # the rest of these I think are an error in how the pooled inventory datasheet is compiled so don't change them for now, they don't exist anyway according to the actual dataset.
    # mutate(sample_name = stringr::str_replace(sample_name, "TMP_SW_POOL_20230612", "TMP_SW_B4_20230612")) %>%
      # Porewater inventory says this is just B4. However, in the raw datafile it doesn't look like this sample exists for DOC.
    #mutate(sample_name = stringr::str_replace(sample_name, "TMP_SW_POOL_20230606", "TMP_SW_C3_20230606")) %>%
      # Porewater inventory says this is just C3. However, in the raw datafile it doesn't look like this sample exists for DOC.
  
reps <- all_samples_dilution_corrected2  %>%
  group_by(sample_name) %>%
  filter(n() > 1) 

print(reps)

reps_names <- reps %>%
  select(sample_name) %>%
  unique() 

samples_dilution_corrected2_no_reps <- all_samples_dilution_corrected2 %>%
  filter(!sample_name %in% reps_names$sample_name)

#need to remove a rep if the following conditions are met:
# 1) Flag says "high blank" &
# 2) Values are > 20% apart 
# If second condition is met but the first is not met, need to flag with "Inconsistent reps"
# If they are close in value, regardless of condition for 1), can be confident that they look good. 

reps_clean <- reps %>%
  group_by(sample_name) %>%
  mutate(doc_mg_l_max = max(doc_mg_l),
         doc_mg_l_min = min(doc_mg_l),
         doc_mg_l_percerr = (doc_mg_l_max - doc_mg_l_min) / doc_mg_l_max,
         Keep_doc = case_when(doc_mg_l_percerr < .25 ~ TRUE),
         tdn_mg_l_max = max(tdn_mg_l),
         tdn_mg_l_min = min(tdn_mg_l),
         tdn_mg_l_percerr = (tdn_mg_l_max - tdn_mg_l_min) / tdn_mg_l_max,
         Keep_tdn = case_when(tdn_mg_l_percerr < .25 ~ TRUE),
         doc_mg_l = case_when(Keep_doc == TRUE ~ doc_mg_l,
                              FALSE ~ NA),
         tdn_mg_l = case_when(Keep_tdn == TRUE ~ tdn_mg_l,
                              FALSE ~ NA)) %>%
  select(sample_name, rundate, doc_mg_l, tdn_mg_l, npoc_flag, tdn_flag) %>%
  group_by(sample_name) %>% 
  summarise(doc_mg_l = mean(doc_mg_l, na.rm = TRUE),
            tdn_mg_l = mean(tdn_mg_l, na.rm = TRUE)) %>%
  mutate(npoc_flag = case_when(doc_mg_l == 'NaN' ~ "replicates greater than 25% different",
                              TRUE ~ "replicates analyzed and values averaged"),
         tdn_flag = case_when(tdn_mg_l == 'NaN' ~ "replicates greater than 25% different",
                              TRUE ~ "replicates analyzed and values averaged"))
#Need to merge those:
npoc_dups_merged <- samples_dilution_corrected2_no_reps %>% 
  bind_rows(reps_clean)

print(npoc_dups_merged)
```

# Clean data 

**someday you should make this a function** 

```{r start cleaning}

## Flagging data
npoc_flags <- npoc_dups_merged %>% 
  ## add flags 
  # Below blank 
  mutate(npoc_flag = case_when(doc_mg_l == 'NaN'& sample_name %in% reps_clean$sample_name ~ "replicates greater than 25% different",
                               sample_name %in% reps_clean$sample_name ~ "average value of multiple aliquots",
                               doc_mg_l == 'NaN' ~ "value below blank",
                               grepl("POOL", sample_name) ~ "pooled sample",
                               grepl("pool", sample_name) ~ "pooled sample",
                               grepl("value above cal curve",npoc_flag) ~ "value above cal curve",
                               TRUE ~ npoc_flag), 
         tdn_flag = case_when(tdn_mg_l == 'NaN'& sample_name %in% reps_clean$sample_name ~ "replicates greater than 25% different",
                              sample_name %in% reps_clean$sample_name ~ "average value of multiple aliquots",
                              tdn_mg_l == 'NaN' ~ "value below blank",
                              grepl("POOL", sample_name) ~ "pooled sample",
                              grepl("pool", sample_name) ~ "pooled sample",
                              grepl("value above cal curve",tdn_flag) ~ "value above cal curve",
                              TRUE ~ tdn_flag)) 

npoc_wflags_metadata.1 <-  npoc_flags %>%
  mutate(sample_name = stringr::str_replace(sample_name,"pooled","POOL"),
         Event = stringr::str_extract(sample_name, "TMP"),
         Plot = stringr::str_extract(sample_name, 'FW|SW|C|ESTUARY'), 
         Grid = stringr::str_extract(sample_name, "B4|C3|C6|D5|E3|F4|F6|H3|H6|I5|SOURCE|ESTUARY|POOL|WELL"),
         Timepoint = stringr::str_extract(sample_name,"T[0-9]|HR[0-9]"),
         Timepoint = case_when(Timepoint == "HR8" ~ "HR7", #change the estuary HR8 to HR7
                                TRUE ~ Timepoint),
         Pool_Timepoint = stringr::str_extract(sample_name,"[0-9]{8}_\\d{8}|[0-9]{8}-\\d{8}"),
         sample_name = stringr::str_remove(sample_name,"(?<=[0-9]{8})_\\d{8}|(?<=[0-9]{8})-\\d{8}"),
         sample_name = stringr::str_remove(sample_name, "_FW\\d{2}|_SW\\d{2}"),
         doc_mg_l = case_when(doc_mg_l == "NaN" ~ NA,
                              TRUE ~ doc_mg_l),
         tdn_mg_l = case_when(tdn_mg_l == "NaN" ~ NA,
                              TRUE ~ tdn_mg_l)
         ) %>%
   mutate(Plot = case_when(Grid == "ESTUARY" ~ "ESTUARY",
                        TRUE ~ Plot)) %>%
  left_join(sample_key_merging, by = c("Plot","Timepoint")) %>%
  mutate(date= case_when(is.na(date) ~ stringr::str_extract(sample_name, "[0-9]{8}"),
                  TRUE ~ date)) %>%
 left_join(non_event_sample_key_merging, by= c("Plot","Grid","date"), suffix = c("", ".fill")) %>%
  mutate(time = coalesce(time, time.fill)) %>%
  select(-time.fill) %>%
  mutate(date = lubridate::as_date(date, format = "%Y%m%d"))

pwsite_key_all <- pwsite_key %>% expand(Plot, Grid, date = unique(npoc_wflags_metadata.1$date)) %>% drop_na()

npoc_wflags_metadata <- npoc_wflags_metadata.1 %>%
   full_join(pwsite_key_all, by=c("Plot","Grid", "date")) %>%  #gap fill with NAs when lysimeters were dry for that sampling timepoint
  mutate(time = case_when(is.na(time) ~ stringr::str_extract(sample_name, "(?<=[0-9]{8}_)\\d{4}"),
                          TRUE ~ time),
         time = str_replace(time, '\\d+', function(m) str_pad(m, 6, pad = '0', side = ("right")))
         ) %>%
  mutate(time = case_when(is.na(time) ~ "115900", 
                          TRUE ~ time)) %>% #if no time recorded in the metadata sheet, fill in with noon
  mutate(time= strptime(time, format ="%H%M%S"),
         time = strftime(time, "%H:%M:%S")) %>%
   mutate(Timepoint = case_when(is.na(Timepoint) & date == "2022-07-18" ~ "T5",
                             is.na(Timepoint) & date == "2022-07-21" ~ "T5",
                             is.na(Timepoint) & date == "2022-06-15" ~ "T0",
                                      TRUE ~ Timepoint)) %>%
  mutate(datetime = as.POSIXct(paste(date, time), format = "%Y-%m-%d %H:%M:%S"))

print(npoc_wflags_metadata)

```

```{r dataframe clean up for various saving}

clean_npoc_wflags_metadata <- npoc_wflags_metadata %>%
  filter(date < endstudydate & date > startstudydate) %>%
  mutate(doc_mg_l = case_when(is.na(sample_name) & is.na(rundate) ~ NA,
                              TRUE ~ doc_mg_l),
         tdn_mg_l = case_when(is.na(sample_name) & is.na(rundate) ~ NA,
                              TRUE ~ tdn_mg_l),
         date = case_when(is.na(sample_name) & Timepoint == "T0" ~ lubridate::as_date("2022-06-20"),
                          is.na(sample_name) & Timepoint == "T1" ~ lubridate::as_date("2022-06-22"),
                          is.na(sample_name) & Timepoint == "T2" ~ lubridate::as_date("2022-06-22"),
                          is.na(sample_name) & Timepoint == "T3" ~ lubridate::as_date("2022-06-23"),
                          is.na(sample_name) & Timepoint == "T4" ~ lubridate::as_date("2022-06-24"),
                          is.na(sample_name) & Timepoint == "T5" ~ lubridate::as_date("2022-07-21"),
                          TRUE ~ date),
         Event = case_when(is.na(Event) ~ "TMP",
                           TRUE ~ Event),
         sample_name = case_when(is.na(sample_name)~ "Lysimeter Empty",
                                 TRUE ~ sample_name)) %>%
  mutate(plot = case_when(Plot == "FW" ~ "Freshwater",
                          Plot == "C" ~ "Control",
                          Plot == "SW" ~ "Estuarine-water",
                          TRUE ~ Plot)) %>%
   mutate(Group=case_when(lubridate::month(date) != 6 ~ as.character(paste(lubridate::year(date), lubridate::month(date), 1, sep = "-")),
                         lubridate::month(date) == 6 ~ as.character(date)))%>%
  mutate(Group = lubridate::as_date(Group))

#Only porewater, all dates:

PW_npoc_wflags_metadata <- clean_npoc_wflags_metadata %>%
  filter(Grid != "SOURCE") %>%
  filter(Grid != "WELL") %>%
  filter(Grid != "ESTUARY") 

#Only porewater POOLED, all dates:
PW_npoc_wflags_metadata_pooled_only <- PW_npoc_wflags_metadata %>%
    filter(date < endstudydate & date > startstudydate) %>%
  filter(Grid == "POOL") %>%
   select(Event, plot, Grid, datetime, Group, sample_name, doc_mg_l, tdn_mg_l, npoc_flag, tdn_flag, Timepoint, Pool_Timepoint)

#Only porewater grids not pooled, all dates:
PW_npoc_wflags_metadata_grids_only <- PW_npoc_wflags_metadata %>%
    filter(date < endstudydate & date > startstudydate) %>%
  filter(Grid != "POOL") %>%
  group_by(date) %>%
  fill(evacuation_date, collection_date) %>%
  mutate(collection_date = case_when(is.na(collection_date) ~ date,
                                     TRUE ~ collection_date)) %>%
  select(Event, plot, Grid, datetime, tz, Group, evacuation_date, collection_date, sample_name, doc_mg_l, tdn_mg_l, npoc_flag, tdn_flag)


#Only sourcewater, all dates:
source_npoc_wflags_metadata <- clean_npoc_wflags_metadata %>%
  filter(date < endstudydate & date > startstudydate) %>%
  filter(grepl("SOURCE|ESTUARY|BARGE", sample_name)) %>%
  select(Event, plot, Grid, datetime, Group, sample_name, doc_mg_l, tdn_mg_l, npoc_flag, tdn_flag)


```

<!-- ##### partially summarized except for june, no event. might be useful for plotting, not sure yet -->

<!-- PW_npoc_wflags_metadata_summarized_noevents <- PW_npoc_wflags_metadata  %>% -->
<!--   filter(date < endstudydate & date > startstudydate) %>% -->
<!--   filter(datetime < WaterDeliveryStart2022 | datetime > WaterDeliveryStop2022) %>% -->
<!--   filter(datetime < WaterDeliveryStart1 | datetime > WaterDeliveryStop1) %>% -->
<!--   filter(datetime < WaterDeliveryStart2 | datetime > WaterDeliveryStop2) %>% -->
<!--   filter(Grid != "POOL") %>% -->
<!--   filter(!sample_name %in% "Lysimeter Empty") %>% -->
<!--   filter(!npoc_flag %in% "omitted for high dilution and blank values") %>% -->
<!--   filter(!tdn_flag %in% "omitted for high dilution and blank values") %>% -->
<!--   mutate( -->
<!--          Group=case_when(lubridate::month(date) != 6 ~ as.character(paste(lubridate::year(date), lubridate::month(date), 1, sep = "-")), -->
<!--                          lubridate::month(date) == 6 ~ as.character(date))) %>% -->
<!--   mutate(Group = lubridate::as_date(Group)) %>% -->
<!--   group_by(plot, Group) %>%  -->
<!--   summarise(n=n(), -->
<!--             doc_mg_l_sd = round(sd(doc_mg_l, na.rm = TRUE), 2), -->
<!--             doc_mg_l_se = round(std.error(doc_mg_l, na.rm=TRUE), 2), -->
<!--             doc_mg_l = round(mean(doc_mg_l, na.rm = TRUE), 2), -->
<!--             tdn_mg_l_sd = round(sd(tdn_mg_l, na.rm = TRUE), 2), -->
<!--             tdn_mg_l_se = round(std.error(tdn_mg_l, na.rm=TRUE), 2), -->
<!--             tdn_mg_l = round(mean(tdn_mg_l, na.rm = TRUE),2), -->
<!--             date = min(date), -->
<!--             .groups = "drop") %>% -->
<!--   select(plot, Group, date, n, doc_mg_l, doc_mg_l_sd, doc_mg_l_se, tdn_mg_l, tdn_mg_l_sd, tdn_mg_l_se)  -->
  
# Write data

### Work up for Manuscript

***Note, this is set up if you run the markdown that it won't actually save the files, to prevent folks from overwritting version of record files when getting familiar with the script.*** 

1) Save the source and pooled DOC data separately from the grid resolved:

```{r manuscript specific write out, eval=FALSE}

saveRDS(source_npoc_wflags_metadata, "~/GitHub/TEMPEST-1-porewater/processed data/TMP_SOURCE_NPOC_TDN_L1_TMP1TMP2.rds")

saveRDS(PW_npoc_wflags_metadata_pooled_only, "~/GitHub/TEMPEST-1-porewater/processed data/TMP_PW_POOL_NPOC_TDN_L1_May2022-Dec2023.rds")

```

2) Save the grid resolved data: 

```{r manuscript specific final write out of pw, eval=FALSE}
for_fluxes <- PW_npoc_wflags_metadata_grids_only %>%
  ungroup() %>%
  rename(grid = Grid,
         collection_datetime = datetime) %>%
  select(Event, plot, grid, sample_name, doc_mg_l, tdn_mg_l, evacuation_date, collection_datetime, tz) %>%
  #manual entry of missing evacuation information from the notes: 
  mutate(evacuation_date = case_when(
    is.na(evacuation_date) & str_detect(collection_datetime, "2022-05-18") ~ as.Date("2022-05-12"),
    is.na(evacuation_date) & str_detect(collection_datetime, "2022-05-20")  ~ as.Date("2022-05-12"), 
    is.na(evacuation_date) & str_detect(collection_datetime, "2022-06-13")  ~ as.Date("2022-06-09"),
    is.na(evacuation_date) & str_detect(collection_datetime, "2022-06-15")  ~ as.Date("2022-06-09"),
    is.na(evacuation_date) & str_detect(collection_datetime, "2022-06-20") ~ as.Date("2022-06-18"),
    is.na(evacuation_date) & str_detect(collection_datetime, "2022-06-22") ~ as.Date("2022-06-22"),
    is.na(evacuation_date) & str_detect(collection_datetime, "2022-06-23") ~ as.Date("2022-06-22"),
    is.na(evacuation_date) & str_detect(collection_datetime, "2022-06-24") ~ as.Date("2022-06-23"),
    is.na(evacuation_date) & str_detect(collection_datetime, "2023-06-05") ~ as.Date("2023-06-03"),
    is.na(evacuation_date) & str_detect(collection_datetime, "2023-10-05") ~ as.Date("2023-10-02"),
    TRUE ~ evacuation_date)) %>%
  filter(collection_datetime != "2022-05-23 11:59:00") %>%
  mutate(set_tz = with_tz(collection_datetime, tzone = "America/New_York"),
         is_dst = dst(set_tz),
    tz = case_when(is.na(tz) &  is_dst == TRUE ~ "EDT",
                   is.na(tz) &  is_dst != TRUE ~ "EST",
                   TRUE ~ tz)) %>%
  select(-set_tz, -is_dst)

write_csv(for_fluxes, "~/GitHub/TEMPEST-1-porewater/processed data/TMP_PW_GRIDSONLY_NPOC_TDN_L1_May2022-Dec2023.csv")

saveRDS(for_fluxes, "~/GitHub/TEMPEST-1-porewater/processed data/TMP_PW_GRIDSONLY_NPOC_TDN_L1_May2022-Dec2023.rds")
```

## Write for Google Drive L1

```{r write, eval=FALSE}

l1_porewater_2022 = for_fluxes %>%
   filter(collection_datetime < year1_stop & collection_datetime > year1_start)

write_csv(l1_porewater_2022, "~/GitHub/TEMPEST-1-porewater/processed data/TMP_PW_GRIDSONLY_NPOC_TDN_L1_2022.csv")


l1_porewater_2023 = for_fluxes %>%
   filter(collection_datetime < year2_stop & collection_datetime > year2_start)

write_csv(l1_porewater_2023, "~/GitHub/TEMPEST-1-porewater/processed data/TMP_PW_GRIDSONLY_NPOC_TDN_L1_2023.csv")

```

