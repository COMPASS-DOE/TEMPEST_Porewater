---
title: "TMP Porewater DOC for Manuscript"
author: "AMP"
date: "`r Sys.Date()`"
output: html_document
---

# NOTE THIS SCRIPT IS ONLY GOOD FOR TMP 1 & TMP 2 up to TMP 3. 
# DO NOT USE THIS SCRIPT FOR TMP 3 and BEYOND

The script has not yet been validated to work beyond YR end of TMP 2. 

***Note: Date times break for an unknown reason even after setting the system time in the setup IF your computer time is NOT on eastern timezone. so, you need to change that if you're not living in eastern time on your computer to prevent this unknown issue from really messing with the data.*** 

This script imports raw data for NPOC and TDN measured using a Shimadzu TOC-L at PNNL MCRL and exports clean, Level 1 QC'ed data. Raw Data are read in from L0 folder on Google Drive. 

Created: 2022-01-15 by Peter Regier for EXCHANGE
Updated: 2022-06-26 by Allison Myers-Pigg for TEMPEST
Updated and adapted for markdown: 2024-02-10 by Allison Myers-Pigg for TEMPEST 2.0
Updated for more accurate volumes/lysimeter timings: 2024-03-04 by Allison Myers-Pigg for Porewater Manuscripts 

#Setup 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, 
                      message = F,
                      warning = F)

# load packages
require(pacman)
pacman::p_load(tidyverse, # keep things tidy
               janitor, # useful for simplifying column names
               googlesheets4, # read_sheet 
               googledrive, # drive_ functions
               plotrix,
               here) 

common_tz = "Etc/GMT+5"

Sys.setenv(TZ = "America/New_York")

getwd()
```

## Set event and study dates: 
```{r event and study dates}
endstudydate = lubridate::as_date("2024-01-31")
startstudydate = lubridate::as_date("2022-05-01")

endstudydate_yr1 = lubridate::as_date("2023-05-31")
startstudydate_yr1 = lubridate::as_date("2022-05-01")

year1_start = lubridate::as_date("2022-01-01")
year1_stop = lubridate::as_date("2022-12-31")

year2_start = lubridate::as_date("2023-01-01")
year2_stop = lubridate::as_date("2023-12-31")

year3_start = lubridate::as_date("2024-01-01")
year3_stop = lubridate::as_date("2024-12-31")

WaterDeliveryStart2022 = as.POSIXct("2022-06-22 05:30:00", tz = "EST")
WaterDeliveryStop2022 = as.POSIXct("2022-06-22 14:30:00", tz = "EST")

WaterDeliveryStart1 = as.POSIXct("2023-06-06 05:30:00", tz = "EST")
WaterDeliveryStop1 = as.POSIXct("2023-06-06 14:30:00", tz = "EST")

WaterDeliveryStart2 = as.POSIXct("2023-06-07 05:30:00", tz = "EST")
WaterDeliveryStop2 = as.POSIXct("2023-06-07 14:30:00", tz = "EST")

plot_order <- c('Control', 'Freshwater','Saltwater')
time_order <- c('Pre', 'Mid','Post')
```

## Pull in TMP system level analysis (2022 event) metadata 

```{r sys}
## Set Github filepath for NPOC raw data files:

#If needed: source("../tempest-system-level-analysis/scripts/02_tmp_doc_processing_2022Event.R")

sample_key <- readRDS("~/GitHub/tempest-system-level-analysis/data/for processing/TMP_Event_June2022_META_PW_SOURCE_DateTime.rds")

pwsite_key <- readxl::read_excel("~/GitHub/tempest-system-level-analysis/data/for processing/porewater_sites_complete_key.xlsx") %>%
  select(Plot, Grid) %>%
  unique()
```

## pull in active porewater tracking inventory sheet: 
```{r rest of metadata}

inventory_directory <- "https://docs.google.com/spreadsheets/d/1sFWq-WKhemPzbOFInqhCu_Lx0lsO6a_Z/edit#gid=496164093"

directory= file.path(here() %>% dirname(), 'TEMPEST-1-Porewater/data_do_not_commit/')

file_path = file.path(directory,"porewaterinventory.xlsx")

drive_download(inventory_directory, path= file_path, overwrite = TRUE)
```

```{r metadata}

non_event_sample_key_grids <- readxl::read_excel(file_path, skip=3, sheet="Porewater - Individual") %>%
  select(Vial_ID, Plot, Volume_mL, Evacuation_date_YYYMMDD, Collection_Date_YYYYMMDD, Collection_Start_Time_24hrs, Collection_End_Time_24hrs, EST_EDT) %>%
    rename(evacuation_date = Evacuation_date_YYYMMDD,
         collection_date = Collection_Date_YYYYMMDD,
         plot = Plot) %>%
  mutate(evacuation_date = lubridate::as_date(as.character(evacuation_date), format = "%Y%m%d"),
         collection_date = lubridate::as_date(as.character(collection_date), format = "%Y%m%d")) %>%
    mutate(grid = stringr::str_extract(Vial_ID, "B4|C3|C6|D5|E3|F4|F6|H3|H6|I5")) %>%
  mutate(evacuation_date = case_when(
    is.na(evacuation_date) & str_detect(collection_date, "2022-05-18") ~ as.Date("2022-05-12"),
    is.na(evacuation_date) & str_detect(collection_date, "2022-05-20")  ~ as.Date("2022-05-12"), 
    is.na(evacuation_date) & str_detect(collection_date, "2022-06-13")  ~ as.Date("2022-06-09"),
    is.na(evacuation_date) & str_detect(collection_date, "2022-06-15")  ~ as.Date("2022-06-09"),
    is.na(evacuation_date) & str_detect(collection_date, "2022-06-20") ~ as.Date("2022-06-18"),
    is.na(evacuation_date) & str_detect(collection_date, "2022-06-22") ~ as.Date("2022-06-22"),
    is.na(evacuation_date) & str_detect(collection_date, "2022-06-23") ~ as.Date("2022-06-22"),
    is.na(evacuation_date) & str_detect(collection_date, "2022-06-24") ~ as.Date("2022-06-23"),
    is.na(evacuation_date) & str_detect(collection_date, "2023-06-05") ~ as.Date("2023-06-03"),
    is.na(evacuation_date) & str_detect(collection_date, "2023-10-05") ~ as.Date("2023-10-02"),
    TRUE ~ evacuation_date)) %>% 
    fill(evacuation_date, collection_date) %>%
    mutate(plot = case_when(plot == "C" ~ "Control",
                           plot == "SW" ~ "Saltwater",
                           plot == "FW" ~ "Freshwater",
                           plot == "Contol" ~ "Control",
                           plot == "Saltwater" ~ "Saltwater",
                          TRUE ~ plot)) %>%
  group_by(plot, grid, evacuation_date, collection_date) %>%
  #fill down exact group matches by group missing values:
  fill(evacuation_date, collection_date, Collection_Start_Time_24hrs, Collection_End_Time_24hrs) %>%
  ungroup() %>%
  #fill down and up by evacuation date match only: 
    group_by(plot, grid, evacuation_date) %>%
    fill(evacuation_date, collection_date, Collection_Start_Time_24hrs, Collection_End_Time_24hrs, .direction ="downup") %>%
  ungroup() %>%
  mutate(Collection_Start_Time_24hrs = str_replace(Collection_Start_Time_24hrs, '\\d+', function(m) str_pad(m, 4, pad = '0', side = ("left"))),
         Collection_End_Time_24hrs = str_replace(Collection_End_Time_24hrs, '\\d+', function(m) str_pad(m, 4, pad = '0', side = ("left")))) %>%
   #NAs present because some groups have no time recorded at all. Enter in a set time for those:
    group_by(plot, grid, evacuation_date, collection_date) %>%
    mutate(Collection_Start_Time_24hrs = case_when(is.na(Collection_Start_Time_24hrs) ~ "1159", 
                          TRUE ~ Collection_Start_Time_24hrs),
           Collection_End_Time_24hrs = case_when(is.na(Collection_End_Time_24hrs) ~ "1159", 
                          TRUE ~ Collection_End_Time_24hrs)) %>% #if no time recorded in the metadata sheet, fill in with noon
  mutate(Collection_Start_Time_24hrs = strptime(Collection_Start_Time_24hrs, format ="%H%M"),
         Collection_Start_Time_24hrs = strftime(Collection_Start_Time_24hrs, "%H:%M:%S"),
         Collection_End_Time_24hrs = strptime(Collection_End_Time_24hrs, format ="%H%M"),
         Collection_End_Time_24hrs = strftime(Collection_End_Time_24hrs, "%H:%M:%S")) %>%
  ungroup() %>%
    mutate(evacuation_datetime = as.POSIXct(paste(evacuation_date, Collection_Start_Time_24hrs), format = "%Y-%m-%d %H:%M:%S"),
         collection_datetime = as.POSIXct(paste(collection_date, Collection_End_Time_24hrs), format = "%Y-%m-%d %H:%M:%S"),
  elapsed_time = collection_datetime - evacuation_datetime) %>%
  rename(tz = EST_EDT) %>%
   mutate(set_tz = with_tz(collection_datetime, tzone = "America/New_York"),
         is_dst = dst(set_tz),
    tz = case_when(is.na(tz) &  is_dst == TRUE ~ "EDT",
                   is.na(tz) &  is_dst != TRUE ~ "EST",
                   TRUE ~ tz)) %>%
  dplyr::select(-set_tz, -is_dst) %>%
  #now need to add together all the other sample volumes but retain the DOC Vial_ID
    mutate(Vial_ID = stringr::str_replace(Vial_ID, "_1of1", "rep1")) %>%
    mutate(Vial_ID = stringr::str_replace(Vial_ID, "_1of2", "rep1")) %>%
    mutate(Vial_ID= stringr::str_replace(Vial_ID, "_2of2", "rep2")) %>%
    mutate(Vial_ID = stringr::str_replace(Vial_ID, "_1of3", "rep1")) %>%
    mutate(Vial_ID = stringr::str_replace(Vial_ID, "_2of3", "rep2")) %>%
    mutate(Vial_ID = stringr::str_replace(Vial_ID, "_3of3", "rep3")) %>%
    mutate(Vial_ID = stringr::str_replace(Vial_ID, "DOC/CDOM", "CDOM")) %>%
  mutate(sample_type = stringr::str_extract(Vial_ID, 'SO4|FE|DOC|NUTR|AMINO|ISO|SAC|HR-MS|CDOM|rep1|rep2|rep3')) %>%
  pivot_wider(names_from = c(sample_type), values_from = c(Volume_mL, Vial_ID)) %>%
  dplyr::select(plot:Volume_mL_rep3, Vial_ID_DOC, Vial_ID_rep1, Vial_ID_rep2, Vial_ID_rep3) %>%
  pivot_longer(cols = starts_with("Vial_ID"), values_to = "Vial_ID") %>%
  dplyr::select(-name) %>%
  mutate(Vial_ID = as.character(Vial_ID),
       Vial_ID = case_when(Vial_ID == "NULL" ~ NA,
                             TRUE ~ Vial_ID)) %>%
  filter(!is.na(Vial_ID)) %>%
  mutate(
         Volume_mL_SO4 = as.numeric(as.character(Volume_mL_SO4)),
         Volume_mL_FE = as.numeric(as.character(Volume_mL_FE)),
         Volume_mL_DOC = as.numeric(as.character(Volume_mL_DOC)),
         Volume_mL_NUTR = as.numeric(as.character(Volume_mL_NUTR)),
         Volume_mL_CDOM = as.numeric(as.character(Volume_mL_CDOM)),
         Volume_mL_ISO = as.numeric(as.character(Volume_mL_ISO)),
         Volume_mL_SAC = as.numeric(as.character(Volume_mL_SAC)),
         Volume_mL_AMINO = as.numeric(as.character(Volume_mL_AMINO)),
         Volume_mL_HR_MS = as.numeric(as.character(`Volume_mL_HR-MS`)),
         Volume_mL_rep1= as.numeric(as.character(Volume_mL_rep1)),
         Volume_mL_rep2 = as.numeric(as.character(Volume_mL_rep2)),
         Volume_mL_rep3 = as.numeric(as.character(Volume_mL_rep3))) %>%
    dplyr::select(Vial_ID, plot:Volume_mL_AMINO, Volume_mL_rep1:Volume_mL_rep3, Volume_mL_HR_MS) %>%
    pivot_longer(cols = c("Volume_mL_SO4", "Volume_mL_FE", "Volume_mL_DOC", "Volume_mL_NUTR", "Volume_mL_CDOM", "Volume_mL_ISO", "Volume_mL_SAC", "Volume_mL_AMINO", "Volume_mL_HR_MS", "Volume_mL_rep1", "Volume_mL_rep2", "Volume_mL_rep3" ),
    names_to = "aliquot",
    values_to = "Volume_mL") %>%
  mutate(Volume_mL = replace_na(Volume_mL, 0)) %>%
  group_by(Vial_ID, plot, grid, evacuation_date, collection_date, evacuation_datetime, collection_datetime, tz, elapsed_time) %>%
 dplyr::summarise(Total_Aliquot_Volume_mL = sum(Volume_mL)) %>%
    mutate(Vial_ID = stringr::str_replace(Vial_ID, "rep1", "")) %>%
    mutate(Vial_ID = stringr::str_replace(Vial_ID, "rep2", "")) %>%
    mutate(Vial_ID= stringr::str_replace(Vial_ID, "rep3", "")) %>%
  #change the AM/PM samplings to match those on the DOC vials:
    mutate(Vial_ID= stringr::str_replace(Vial_ID, "_AM", "_0800")) %>%
    mutate(Vial_ID= stringr::str_replace(Vial_ID, "_PM", "_1600")) %>%
  #remove weird _1 and _2 after some names: 
    mutate(Vial_ID= stringr::str_replace(Vial_ID, "_20231208_1", "_20231208")) %>%
    mutate(Vial_ID= stringr::str_replace(Vial_ID, "20231211_2", "20231211")) %>%
  #change dates in vial_IDs to match DOC vials:
   mutate(Vial_ID= stringr::str_replace(Vial_ID, "TMP_FW_E3_20220520", "TMP_FW_E3_20220518")) %>%
   mutate(Vial_ID= stringr::str_replace(Vial_ID, "TMP_C_I5_20231002", "TMP_C_I5_20231005")) 

  

### Pooled ####
pooled_vols <- readxl::read_excel(file_path, skip=4, sheet="Porewater - Pooled") %>%
  select(Sample_ID, Total_Volume_mL, Grid_C3:Grid_I5, Evacuation_date_YYYMMDD, Collection_Date_YYYYMMDD) %>%
  mutate(across(starts_with("Grid"), ~ ifelse(is.na(.),0,.))) %>%
  mutate(Plot = stringr::str_extract(Sample_ID, 'FW|SW|C')) %>%
   pivot_longer(cols = c("Grid_C3", "Grid_C6", "Grid_F4", "Grid_H3", "Grid_H6", "Grid_B4", "Grid_D5", "Grid_E3", "Grid_F6", "Grid_I5"),
    names_to = "grid",
    values_to = "Volume_mL") %>%
   mutate(plot = case_when(Plot == "C" ~ "Control",
                           Plot == "SW" ~ "Saltwater",
                           Plot == "FW" ~ "Freshwater",
                           Plot == "Saltwater" ~ "Saltwater",
                          TRUE ~ Plot),
          grid = str_remove(grid, "Grid_")) %>%
  rename(evacuation_date = Evacuation_date_YYYMMDD,
         collection_date = Collection_Date_YYYYMMDD) %>%
  mutate(evacuation_date = lubridate::as_date(as.character(evacuation_date), format = "%Y%m%d"),
         collection_date = lubridate::as_date(as.character(collection_date), format = "%Y%m%d"),
         date = stringr::str_extract(Sample_ID, "[0-9]{8}")) %>%
  mutate(date = lubridate::as_date(date, format = "%Y%m%d")) %>%
  mutate(set_tz = with_tz(collection_date, tzone = "America/New_York"),
         is_dst = dst(set_tz),
    tz = case_when(is_dst == TRUE ~ "EDT",
                   is_dst != TRUE ~ "EST")) %>%
  select(-set_tz, -is_dst) %>%
  group_by(date) %>%
   #manual entry of missing evacuation information from the notes: 
  mutate(evacuation_date = case_when(
    is.na(evacuation_date) & str_detect(collection_date, "2022-05-18") ~ as.Date("2022-05-12"),
    is.na(evacuation_date) & str_detect(collection_date, "2022-05-20")  ~ as.Date("2022-05-12"), 
    is.na(evacuation_date) & str_detect(collection_date, "2022-06-13")  ~ as.Date("2022-06-09"),
    is.na(evacuation_date) & str_detect(collection_date, "2022-06-15")  ~ as.Date("2022-06-09"),
    is.na(evacuation_date) & str_detect(collection_date, "2022-06-20") ~ as.Date("2022-06-18"),
    is.na(evacuation_date) & str_detect(collection_date, "2022-06-22") ~ as.Date("2022-06-22"),
    is.na(evacuation_date) & str_detect(collection_date, "2022-06-23") ~ as.Date("2022-06-22"),
    is.na(evacuation_date) & str_detect(collection_date, "2022-06-24") ~ as.Date("2022-06-23"),
    is.na(evacuation_date) & str_detect(collection_date, "2023-06-05") ~ as.Date("2023-06-03"),
    is.na(evacuation_date) & str_detect(collection_date, "2023-10-05") ~ as.Date("2023-10-02"),
    TRUE ~ evacuation_date)) %>%
  fill(evacuation_date, collection_date) %>%
  #Empty dates for the event dates, those are when collection and evacuation are usually the same date: 
  mutate(collection_date = case_when(is.na(collection_date) ~ date,
                                     TRUE ~ collection_date),
         evacuation_date = case_when(is.na(evacuation_date) ~ date,
                                     TRUE ~ evacuation_date)) %>%
  ungroup() %>%
  select(Sample_ID, plot, grid, Total_Volume_mL, Volume_mL, evacuation_date, collection_date, tz) %>%
  filter(Volume_mL > 0) %>%
  pivot_wider(names_from = c(grid), names_prefix = "Pooled_vol_mL_from_", values_from = c(Volume_mL)) %>%
   filter(collection_date < year2_stop & collection_date > year1_start) %>%
    mutate(across(everything(), ~replace_na(.x, 0))) %>%
  #rename to match DOC data
  mutate(Sample_ID = stringr::str_replace(Sample_ID,"POOLED","POOL")) %>%
  #fix all the incorrectly entered metadata names to better match DOC data
  mutate(Sample_ID = stringr::str_replace(Sample_ID, "202312", "20231211")) %>%
  mutate(Sample_ID = stringr::str_replace(Sample_ID, "202310", "20231002")) %>%
  mutate(Sample_ID = stringr::str_replace(Sample_ID, "202308", "20230807")) %>%
  mutate(Sample_ID = stringr::str_replace(Sample_ID, "202307", "20230707")) %>%
  mutate(Sample_ID = stringr::str_replace(Sample_ID, "202302", "20230202")) %>%
  mutate(Sample_ID = stringr::str_replace(Sample_ID, "202211-12", "20221128")) %>%
  mutate(Sample_ID = stringr::str_replace(Sample_ID, "20221019-24", "20221019")) %>%
  mutate(Sample_ID = stringr::str_replace(Sample_ID, "20220915", "20220912")) %>%
  rename(Vial_ID = Sample_ID)

non_event_sample_key <- non_event_sample_key_grids %>% 
  mutate(grid = case_when(is.na(grid) ~ stringr::str_extract(Vial_ID, "B4|C3|C6|D5|E3|F4|F6|H3|H6|I5|SOURCE|ESTUARY|POOL|WELL"),
                          TRUE ~ grid)) %>%
  mutate(time = format(collection_datetime, format = "%H:%M:%S")) 

POOLED_non_event_sample_key <- pooled_vols %>% 
  mutate(grid = stringr::str_extract(Vial_ID, "B4|C3|C6|D5|E3|F4|F6|H3|H6|I5|SOURCE|ESTUARY|POOL|WELL"))
  
```

```{r TEMPEST 1 sample key}
## add into here time points for pre and post sampling for gapfilling purposes later on
estuary_key1 = tibble(Plot = "ESTUARY",
                     Timepoint = "HR4", 
                     date = "20220622", 
                     time= "110000")

estuary_key2 = tibble(Plot = "ESTUARY",
                     Timepoint = "HR7", 
                     date = "20220622", 
                     time= "150000")

### get ready for merging: 
sample_key_merging <- sample_key %>%
  mutate(date = stringr::str_remove_all(Date, "-")) %>%
  rename(time = Start_time) %>%
  mutate(time = str_replace_all(time, ":", "")) %>%
  select(Plot,Timepoint, date, time) %>%
  bind_rows(estuary_key1,estuary_key2) %>%
  mutate(time = str_replace(time, "^[0-9]{5}$", function(x) paste0("0",x)))


non_event_sample_key_merging <- non_event_sample_key %>%
  rename(sample_name = Vial_ID,
         Plot = plot,
         Grid = grid) %>%
  mutate( #for merging with DOC data
         date = stringr::str_extract(sample_name, "[0-9]{8}")
        # time = str_replace(time, "^[0-9]{3}$", function(x) paste0("0", x, "00")),
       #  time = str_replace(time, "^[0-9]{4}$", function(x) paste0(x, "00"))
         ) %>%
  ungroup() %>%
  #get the names cleaned up to better match what's going on in the DOC dataframe:
  mutate(sample_name = str_remove(sample_name, "_15cm"),
         sample_name = str_remove(sample_name, "DOC_"),
         sample_name = str_remove(sample_name, "_PW"),
         sample_name = case_when(str_detect(sample_name, "TMP", negate = TRUE) ~ paste0("TMP_", sample_name),
                                 TRUE ~ sample_name)) %>%
  mutate(sample_name = stringr::str_replace(sample_name, "TMP_C_F4_20221128", "TMP_C_F6_20221128")) %>% # nov/dec C F6 naming mix up with F4 in DOC run
  select(sample_name, Plot, Grid, date, time, tz, evacuation_date, collection_date, evacuation_datetime, collection_datetime, elapsed_time, Total_Aliquot_Volume_mL) 

#pooled 
pooled_sample_key_merging <- POOLED_non_event_sample_key %>%
  rename(sample_name = Vial_ID,
         Plot = plot,
         Grid = grid) %>%
  mutate( #for merging with DOC data
         date = stringr::str_extract(sample_name, "[0-9]{8}")
        # time = str_replace(time, "^[0-9]{3}$", function(x) paste0("0", x, "00")),
       #  time = str_replace(time, "^[0-9]{4}$", function(x) paste0(x, "00"))
         ) %>%
  ungroup() %>%
  #get the names cleaned up to better match what's going on in the DOC dataframe:
    mutate(sample_name = str_remove(sample_name, "_15cm"),
         sample_name = str_remove(sample_name, "DOC_"),
         sample_name = str_remove(sample_name, "_PW"),
         sample_name = case_when(str_detect(sample_name, "TMP", negate = TRUE) ~ paste0("TMP_", sample_name),
                                 TRUE ~ sample_name)) %>%
    #change the AM/PM samplings to match those on the DOC vials:
      mutate(sample_name = stringr::str_replace(sample_name, "_AM", "_0800")) %>%
      mutate(sample_name = stringr::str_replace(sample_name, "_PM", "_1600")) %>%
      mutate(sample_name = case_when(sample_name == "TMP_FW_POOL_202310" ~ "TMP_FW_POOL_20231002", #this didn't have a date in the sample name
                              TRUE ~ sample_name)) %>%
      mutate(sample_name = case_when(sample_name == "TMP_SW_POOL_202310" ~ "TMP_SW_POOL_20231002", #this didn't have a date in the sample name
                              TRUE ~ sample_name)) %>%
     mutate(sample_name = case_when(sample_name == "TMP_FW_POOL_202312" ~ "TMP_FW_POOL_20231211", #this didn't have a date in the sample name
                              TRUE ~ sample_name)) %>%
       mutate(sample_name = case_when(sample_name == "TMP_SW_POOL_202312" ~ "TMP_SW_POOL_20231211", #this didn't have a date in the sample name
                              TRUE ~ sample_name)) %>%
       mutate(sample_name = case_when(sample_name == "TMP_C_POOL_202312" ~ "TMP_C_POOL_20231211", #this didn't have a date in the sample name
                              TRUE ~ sample_name))
```


<!-- {r read in and save files from google drive} -->

<!-- raw_data_path <- "./data_do_not_commit/doc_L0_fromdrive/" -->

<!--  l0_file_list <- drive_ls("https://drive.google.com/drive/folders/1P65nP0CFY8V1iEY47O_fnNhvNS6D6eNt") -->

<!--  currently having issues getting this to work going to use the data already on github for this for now -->

<!-- {r Pull L0 data from Gdrive, eval = F} -->
<!--   # Only use this chunk if you've not saved the data into github previously, pull from drive -->
<!--   # pulled down the data I want, and it takes a while to run since the files are big -->

<!-- drive_download_ <- function(data){ -->
<!--   message(paste("Downloading", data$name)) -->
<!--   # you could add an ifelse to only download files it doesn't fine in raw_data_path -->
<!-- drive_download( -->
<!-- as_id(data$id), overwrite = T, path = paste0(raw_data_path, data$name)) -->
<!-- } -->

<!--  # Use a for-loop to read in files in a way that I can see what's going on -->
<!--  # Download data to local. I tried to map() but for some reasons it doesn't work? -->

<!-- for(i in 1:nrow(l0_file_list)){ -->
<!--    drive_download_(l0_file_list %>% slice(i)) -->
<!--  }  -->
 

## Set Github filepath for NPOC raw data files - this is temporary - in ideal world we would be doing the previous steps

```{r github directory}
directory= file.path(here() %>% dirname(), 'tempest-system-level-analysis/data/raw/DOC')

```

# Functions

```{r functions, include=FALSE}
## Create a function to read in data
read_data <- function(data){
  # First, scrape date from filename
  rundate <- str_extract(data, "[0-9]{8}")
  # Second, read in data
  read_delim(file = data, skip = 10, delim = "\t", show_col_types = FALSE) %>% 
    rename(sample_name = `Sample Name`, 
           npoc_raw = `Result(NPOC)`, 
           tdn_raw = `Result(TN)`,
           run_datetime = `Date / Time`) %>% 
    select(sample_name, npoc_raw, tdn_raw,run_datetime) %>% 
    mutate(rundate = rundate)
}

read_mes <- function(readme){
  # First, scrape date from filename
  rundate <- str_extract(readme, "[0-9]{8}")
  # Second, read in Read Me
  readxl::read_excel(path = readme, sheet = 1) %>% 
    rename(sample_name = `Sample Name`,
           sample_vol = `Sample wt`,
           total_vol = `Total vol:`) %>% 
    select(sample_name, Action, sample_vol, total_vol) %>% 
    mutate(rundate = rundate)
}
```

# Review files 

```{r figure out files to use, include=TRUE}
files <- list.files(path = here::here(directory), pattern = "Summary", full.names = TRUE) 
ReadMes <- list.files(path = here::here(directory), pattern = "Readme", full.names = TRUE) 

files
```

# Import Data
```{r import data, include= TRUE, message=FALSE, warning=FALSE}

npoc_raw <- files %>% 
  map_df(read_data) %>% 
  filter(grepl("TMP", sample_name)) %>% # filter to TMP samples only
#  filter(rundate %in% files_dates) %>% # filter to just run dates you need 
  bind_rows() 

blanks_raw <- files %>% 
  map_df(read_data) %>% 
  filter(grepl("^Blank", sample_name)) %>% # filter to blanks only
#  filter(rundate %in% files_dates) %>% # filter to just run dates you need 
  bind_rows() 

checks_raw <- files %>% 
  map_df(read_data) %>% 
  filter(grepl("CK", sample_name)) %>% # filter to blanks only
#  filter(rundate %in% files_dates) %>% # filter to just run dates you need 
  bind_rows() 

readmes_dilution_action <- ReadMes %>% 
  map_df(read_mes) %>% 
  filter(grepl("TMP", sample_name)) %>% # filter to TMP samples only
  filter(grepl("ilution correction", Action)) %>%
#  filter(rundate %in% files_dates) %>% # filter to just run dates you need 
  bind_rows() 

readmes_all <- ReadMes %>% 
  map_df(read_mes) %>% 
  filter(grepl("TMP", sample_name)) %>% # filter to TMP samples only
#  filter(rundate %in% files_dates) %>% # filter to just run dates you need 
    mutate(Action = case_when(sample_name == "TMP_SW_F4_T3" ~ "Omit", # due to incorrect duplicate naming
                            sample_name == "TMP_ESTUARY_BARGE_HR8_DOC" & rundate == "20220629" ~ "Omit", #remove this weird sample that should have been flagged because its basically 0
                              TRUE ~ Action)) %>%
  bind_rows() 

curvepts <-files %>% 
  map_df(read_data) %>% 
  filter(grepl("ppm|std", sample_name, ignore.case = TRUE) & !grepl("CK", sample_name, ignore.case = TRUE)) %>% # filter to curves only
#  filter(rundate %in% files_dates) %>% # filter to just run dates you need 
  filter(!grepl("10/25/2022 7:24:33 PM|9/22/2022 9:03:23 PM", run_datetime)) %>% # filter out curve points you don't want
  rename(standard_high_C = npoc_raw,
         standard_high_N = tdn_raw) %>%
  select(rundate,standard_high_C,standard_high_N) %>%
  pivot_longer(cols = c(standard_high_C,standard_high_N)) %>%
  na.omit() %>%
  group_by(rundate) %>%
  distinct()%>%
  pivot_wider(names_from= name, values_from = value)%>%
  bind_rows() 
```

# Calculate blanks and add to data

```{r blanks}
blanks <- blanks_raw %>% 
  filter(!run_datetime %in% NA) %>% 
  mutate(npoc_raw = ifelse(npoc_raw > 0, npoc_raw, NA)) %>%
  mutate(tdn_raw = ifelse(tdn_raw > 0, tdn_raw, NA)) %>%
  group_by(rundate) %>% 
  summarize(npoc_blank= round(mean(npoc_raw[!is.na(npoc_raw)]), 2),
            npoc_blank_SD= round(sd(npoc_raw[!is.na(npoc_raw)]), 2), #add SD columns
            tdn_blank= round(mean(tdn_raw[!is.na(tdn_raw)]), 2),
            tdn_blank_SD= round(sd(tdn_raw[!is.na(tdn_raw)]), 2)) %>% #add SD columns
  select(rundate, npoc_blank, npoc_blank_SD, tdn_blank, tdn_blank_SD)

print(blanks) # Check out the blank data 
```
# Check out check standards

```{r checks}
checks <- checks_raw %>% 
  filter(!run_datetime %in% NA) %>% 
  mutate(npoc_raw = ifelse(npoc_raw > 0, npoc_raw, NA)) %>%
  mutate(tdn_raw = ifelse(tdn_raw > 0, tdn_raw, NA)) %>%
  mutate(standard_values = as.numeric(str_extract(sample_name, "(?i)(\\d+)(?=ppm)")),
         percent_error_C = abs((npoc_raw - standard_values) / standard_values) * 100,
         percent_error_N = abs((tdn_raw - standard_values) / standard_values) * 100,
         ppm_error_C = abs((npoc_raw - standard_values)),
         ppm_error_N = abs((tdn_raw - standard_values))) %>%
  group_by(rundate) %>% 
  summarize(percent_error_C_avg = round(mean(percent_error_C[!is.na(percent_error_C)]), 2),
            percent_error_C_sd = round(sd(percent_error_C[!is.na(percent_error_C)]), 2))

print(checks) # Check out the check standards overall error and std 
```

# Flag sketch data 

someday you should make this a function 

```{r flagging} 
npoc_flagged <- npoc_raw %>% 
  filter(grepl("TMP", sample_name)) %>% # filter to TMP samples only
  inner_join(blanks, by = "rundate") %>% 
  inner_join(curvepts, by= "rundate") %>%
  mutate(tdn_flag = case_when(tdn_raw > standard_high_N ~ "value above cal curve",
                              tdn_blank > 0.25*tdn_raw ~ "blank is ≥ 25% of sample value", # flagging if blank concentration is > 20% of the sample concentration 
                               sample_name == "TMP_SW_F4_T3" ~ "incorrect sample naming, cannot resolve"), 
         #most curves only to 50, those samples were not above it. making 100 for the August and September, which used 0-100
         npoc_flag = case_when(npoc_raw > standard_high_C ~ "value above cal curve",
                               npoc_blank > 0.25*npoc_raw ~ "blank is ≥ 25% of sample value", # flagging if blank concentration is > 20% of the sample concentration
                              sample_name == "TMP_SW_F4_T3" ~ "incorrect sample naming, cannot resolve"),
          npoc_raw = case_when(npoc_flag == "incorrect sample naming, cannot resolve" ~ NA,
                               TRUE ~ npoc_raw),
          tdn_raw = case_when(tdn_flag == "incorrect sample naming, cannot resolve" ~ NA,
                              TRUE ~ tdn_raw)
  )

print(npoc_flagged)
```

# Dilution Corrections & Flagging 


**someday you should make this a function** 

Some of the pooled samples are actually not pooled and only one lysimeter. These should be incorporated herein so if they are replicates of a DOC value from an individual lysimeter they are incorporated into the values, and then removed as a "Pooled" sample. 

```{r dilutions}
dilutions = 
  readmes_dilution_action %>% 
  mutate(Dilution =  total_vol/sample_vol) %>% 
  dplyr::select(rundate, sample_name, Action, Dilution) %>% 
  force()

samples_to_dilution_corrected = 
  npoc_flagged %>%
  left_join(dilutions, by = c("sample_name", "rundate")) %>% 
  filter(grepl("ilution correction", Action)) %>%
  filter(!Action %in% "Omit") %>% 
  filter(!Action %in% "omit") %>% 
  mutate(doc_mg_l= npoc_raw * Dilution, tdn_mg_l = tdn_raw * Dilution, # True concentration = diluted concentration * total vol / sample vol
         doc_mg_l = as.numeric(doc_mg_l), doc_mg_l = round(doc_mg_l, 2),
         tdn_mg_l= as.numeric(tdn_mg_l), tdn_mg_l= round(tdn_mg_l, 2)) %>%
  mutate(doc_mg_l = case_when(Dilution > 30 & npoc_flag == "blank is ≥ 25% of sample value" ~ NA,
                              TRUE ~ doc_mg_l), # removing values if high blanks and high dilution ratios, potentially large source of error. 
         npoc_flag = case_when(is.na(doc_mg_l) ~ "omitted for high dilution and blank values",
                               TRUE ~ npoc_flag),
         tdn_mg_l = case_when(Dilution > 30 & tdn_flag == "blank is ≥ 25% of sample value" ~ NA,
                              TRUE ~ tdn_mg_l),
         tdn_flag = case_when(is.na(tdn_mg_l) ~ "omitted for high dilution and blank values",
                              TRUE ~ tdn_flag)) # removing values if high blanks and high dilution ratios, potentially large source of error. 

all_samples_dilution_corrected =
  npoc_flagged %>%
  left_join(readmes_all, by = c("sample_name", "rundate")) %>% 
  mutate(doc_mg_l = npoc_raw, tdn_mg_l = tdn_raw) %>%
  filter(!grepl("ilution correction", Action)) %>% 
  filter(!Action %in% "Omit") %>%
  filter(!Action %in% "omit") %>% 
  bind_rows(samples_to_dilution_corrected) %>%
  dplyr::select(sample_name, rundate, doc_mg_l, tdn_mg_l, npoc_flag, tdn_flag)%>%
  mutate(doc_mg_l = if_else(doc_mg_l < 0, "NA", as.character(doc_mg_l)),
         tdn_mg_l = if_else(tdn_mg_l < 0, "NA", as.character(tdn_mg_l)),
         doc_mg_l = as.numeric(doc_mg_l), doc_mg_l = round(doc_mg_l, 2),
         tdn_mg_l= as.numeric(tdn_mg_l), tdn_mg_l= round(tdn_mg_l, 2))

#Identify if any duplicates were run, this should return an empty data frame if not:#

duplicates <- all_samples_dilution_corrected %>% subset(duplicated(sample_name))

print(duplicates)
```

#MANUALLY Fix sample names and see if there were multiple of the same sample split for some reason run:

```{r fix names}
 all_samples_dilution_corrected2 <- all_samples_dilution_corrected %>% 
   #2022 event naming was a hot mess: 
    mutate(sample_name = stringr::str_replace(sample_name,"HR6","HR7")) %>% #HR6 samples are mislabeled, should be HR7
    mutate(sample_name = stringr::str_replace(sample_name, "_DILUTED4mLsmpl3mLwater", "")) %>%
    mutate(sample_name = stringr::str_replace(sample_name, "_Diluted", "")) %>%
    mutate(sample_name = stringr::str_replace(sample_name, "_1of1", "")) %>%
    mutate(sample_name = stringr::str_replace(sample_name, "_1of2", "")) %>%
    mutate(sample_name = stringr::str_replace(sample_name, "_2of2", "")) %>%
    mutate(sample_name = stringr::str_replace(sample_name, "_1of3", "")) %>%
    mutate(sample_name = stringr::str_replace(sample_name, "_2of3", "")) %>%
    mutate(sample_name = stringr::str_replace(sample_name, "_3of3", "")) %>%
    mutate(sample_name = stringr::str_replace(sample_name, "PreW", "T0")) %>%
    mutate(sample_name = stringr::str_replace(sample_name, "TMP_C_F4_20221128", "TMP_C_F6_20221128")) %>% # nov/dec C F6 naming mix up with F4 in DOC run
   mutate(sample_name = stringr::str_replace(sample_name, "TMP_FW_F4_20230606_0800", "TMP_FW_F4_20230606")) %>% #metadata only has PM sampling for lysimeters from 20230606 so removing the AM part of the name
      mutate(sample_name = case_when(sample_name == "TMP_FW_POOL_202310" ~ "TMP_FW_POOL_20231002", #this didn't have a date in the sample name
                              TRUE ~ sample_name)) %>%
    mutate(sample_name = case_when(sample_name == "TMP_SW_POOL_202310" ~ "TMP_SW_POOL_20231002", #this didn't have a date in the sample name
                              TRUE ~ sample_name)) %>%
        mutate(sample_name = case_when(sample_name == "TMP_FW_POOL_202312" ~ "TMP_FW_POOL_20231211", #this didn't have a date in the sample name
                              TRUE ~ sample_name)) %>%
       mutate(sample_name = case_when(sample_name == "TMP_SW_POOL_202312" ~ "TMP_SW_POOL_20231211", #this didn't have a date in the sample name
                              TRUE ~ sample_name)) %>%
       mutate(sample_name = case_when(sample_name == "TMP_C_POOL_202312" ~ "TMP_C_POOL_20231211", #this didn't have a date in the sample name
                              TRUE ~ sample_name)) %>%
   #Relevant Beyond the 2022 Event: 
    mutate(sample_name = stringr::str_remove(sample_name,"_DOC")) %>%
    mutate(sample_name = stringr::str_remove(sample_name,"_A$")) %>%
    mutate(sample_name = stringr::str_remove(sample_name, "_B$")) %>%
    mutate(sample_name = stringr::str_remove(sample_name,"_EXTRA")) %>%
    mutate(sample_name = stringr::str_replace(sample_name,"POOLED","POOL")) %>%
   mutate(sample_name = stringr::str_replace(sample_name,"pooled","POOL")) %>%
    mutate(sample_name = stringr::str_remove(sample_name,"_Subsample")) %>% #WHAT ARE THESE???????
   #These are the pooled samples that are not actually pooled:
    mutate(sample_name = stringr::str_replace(sample_name, "TMP_C_POOL_T2", "TMP_C_H6_T2"))
      # control pooled T2 is actually not a pooled sample - field metadata sheets have that sample coming from one grid: H6
 # the rest of these I think are an error in how the pooled inventory datasheet is compiled so don't change them for now, they don't exist anyway according to the actual dataset.
    # mutate(sample_name = stringr::str_replace(sample_name, "TMP_SW_POOL_20230612", "TMP_SW_B4_20230612")) %>%
      # Porewater inventory says this is just B4. However, in the raw datafile it doesn't look like this sample exists for DOC.
    #mutate(sample_name = stringr::str_replace(sample_name, "TMP_SW_POOL_20230606", "TMP_SW_C3_20230606")) %>%
      # Porewater inventory says this is just C3. However, in the raw datafile it doesn't look like this sample exists for DOC.
  
reps <- all_samples_dilution_corrected2  %>%
  group_by(sample_name) %>%
  filter(n() > 1) 

print(reps)

reps_names <- reps %>%
  select(sample_name) %>%
  unique() 

samples_dilution_corrected2_no_reps <- all_samples_dilution_corrected2 %>%
  filter(!sample_name %in% reps_names$sample_name)
```

### Clean reps to integrate back in with rest of dataset
need to remove a rep if the following conditions are met:
 1) Flag says "high blank" &
 2) Values are > 20% apart 
 If second condition is met but the first is not met, need to flag with "Inconsistent reps"
 If they are close in value, regardless of condition for 1), can be confident that they look good. 
 
```{r clean reps}
reps_clean <- reps %>%
  group_by(sample_name) %>%
  mutate(doc_mg_l_max = max(doc_mg_l),
         doc_mg_l_min = min(doc_mg_l),
         doc_mg_l_percerr = (doc_mg_l_max - doc_mg_l_min) / doc_mg_l_max,
         Keep_doc = case_when(doc_mg_l_percerr < .25 ~ TRUE),
         tdn_mg_l_max = max(tdn_mg_l),
         tdn_mg_l_min = min(tdn_mg_l),
         tdn_mg_l_percerr = (tdn_mg_l_max - tdn_mg_l_min) / tdn_mg_l_max,
         Keep_tdn = case_when(tdn_mg_l_percerr < .25 ~ TRUE),
         doc_mg_l = case_when(Keep_doc == TRUE ~ doc_mg_l,
                              FALSE ~ NA),
         tdn_mg_l = case_when(Keep_tdn == TRUE ~ tdn_mg_l,
                              FALSE ~ NA)) %>%
  select(sample_name, rundate, doc_mg_l, tdn_mg_l, npoc_flag, tdn_flag) %>%
  group_by(sample_name) %>% 
  summarise(doc_mg_l = mean(doc_mg_l, na.rm = TRUE),
            tdn_mg_l = mean(tdn_mg_l, na.rm = TRUE)) %>%
  mutate(npoc_flag = case_when(doc_mg_l == 'NaN' ~ "replicates greater than 25% different",
                              TRUE ~ "replicates analyzed and values averaged"),
         tdn_flag = case_when(tdn_mg_l == 'NaN' ~ "replicates greater than 25% different",
                              TRUE ~ "replicates analyzed and values averaged"))
#Need to merge those:
npoc_dups_merged <- samples_dilution_corrected2_no_reps %>% 
  bind_rows(reps_clean)

print(npoc_dups_merged)
```

# Clean data 

**someday you should make this a function** 

```{r start cleaning}

## Flagging data
npoc_flags <- npoc_dups_merged %>% 
  ## add flags 
  # Below blank 
  mutate(npoc_flag = case_when(doc_mg_l == 'NaN'& sample_name %in% reps_clean$sample_name ~ "replicates greater than 25% different",
                               sample_name %in% reps_clean$sample_name ~ "average value of multiple aliquots",
                               doc_mg_l == 'NaN' ~ "value below blank",
                               grepl("POOL", sample_name) ~ "pooled sample",
                               grepl("pool", sample_name) ~ "pooled sample",
                               grepl("value above cal curve",npoc_flag) ~ "value above cal curve",
                               TRUE ~ npoc_flag), 
         tdn_flag = case_when(tdn_mg_l == 'NaN'& sample_name %in% reps_clean$sample_name ~ "replicates greater than 25% different",
                              sample_name %in% reps_clean$sample_name ~ "average value of multiple aliquots",
                              tdn_mg_l == 'NaN' ~ "value below blank",
                              grepl("POOL", sample_name) ~ "pooled sample",
                              grepl("pool", sample_name) ~ "pooled sample",
                              grepl("value above cal curve",tdn_flag) ~ "value above cal curve",
                              TRUE ~ tdn_flag)) 
```


# Add in metadata 
```{r add in metadata}

npoc_wflags_metadata.1 <-  npoc_flags %>%
  mutate(sample_name = stringr::str_replace(sample_name,"pooled","POOL"),
         Event = stringr::str_extract(sample_name, "TMP"),
         Plot = stringr::str_extract(sample_name, 'FW|SW|C|ESTUARY'), 
         Grid = stringr::str_extract(sample_name, "B4|C3|C6|D5|E3|F4|F6|H3|H6|I5|SOURCE|ESTUARY|POOL|WELL"),
         Timepoint = stringr::str_extract(sample_name,"T[0-9]|HR[0-9]"),
         Timepoint = case_when(Timepoint == "HR8" ~ "HR7", #change the estuary HR8 to HR7
                                TRUE ~ Timepoint),
         Pool_Timepoint = stringr::str_extract(sample_name,"[0-9]{8}_\\d{8}|[0-9]{8}-\\d{8}"),
         sample_name = stringr::str_remove(sample_name,"(?<=[0-9]{8})_\\d{8}|(?<=[0-9]{8})-\\d{8}"),
         sample_name = stringr::str_remove(sample_name, "_FW\\d{2}|_SW\\d{2}"),
         doc_mg_l = case_when(doc_mg_l == "NaN" ~ NA,
                              TRUE ~ doc_mg_l),
         tdn_mg_l = case_when(tdn_mg_l == "NaN" ~ NA,
                              TRUE ~ tdn_mg_l)
         ) %>%
   mutate(Plot = case_when(Grid == "ESTUARY" ~ "ESTUARY",
                        TRUE ~ Plot)) %>%
  # 2022 event metadata: 
  left_join(sample_key_merging, by = c("Plot","Timepoint")) %>%
  mutate(date = case_when(is.na(date) ~ stringr::str_extract(sample_name, "[0-9]{8}"),
                  TRUE ~ date)) %>%
  #need to manually add in some of the 2022 event metadata since it wasn't recorded in the tracking sheet
     mutate(Timepoint = case_when(is.na(Timepoint) & date == "20220718" ~ "T5",
                             is.na(Timepoint) & date == "20220721" ~ "T5",
                             is.na(Timepoint) & date == "20220615" ~ "T0",
                                      TRUE ~ Timepoint),
               date = case_when(is.na(sample_name) & Timepoint == "T0" ~ "20220620",
                          is.na(sample_name) & Timepoint == "T1" ~ "20220622",
                          is.na(sample_name) & Timepoint == "T2" ~ "20220622",
                          is.na(sample_name) & Timepoint == "T3" ~ "20220623",
                          is.na(sample_name) & Timepoint == "T4" ~ "20220624",
                          is.na(sample_name) & Timepoint == "T5" ~ "20220721",
                          TRUE ~ date)) %>%
  mutate(Plot = case_when(Plot == "FW" ~ "Freshwater",
                          Plot == "C" ~ "Control",
                          Plot == "SW" ~ "Saltwater",
                          TRUE ~ Plot))
  

#### FILTER TO POREWATER GRIDS ONLY: ####
porewater_grids_wmeta <- npoc_wflags_metadata.1 %>%
  filter(Grid != "SOURCE") %>%
  filter(Grid != "WELL") %>%
  filter(Grid != "ESTUARY") %>%
  filter(Grid != "POOL") %>%
  #merge with metadata for non-pooled lysimeters:
  left_join(non_event_sample_key_merging, by= c("sample_name","Plot","Grid","date"), suffix = c("", ".fill")) %>%
  mutate(time = strftime(strptime(time, "%H%M%S"), "%H:%M:%S")) %>%
  mutate(time = coalesce(time, time.fill)) %>%
  select(-time.fill) %>%
  mutate(date = lubridate::as_date(date, format = "%Y%m%d")) %>%
  mutate(collection_date = case_when(is.na(collection_date) ~ date,
                  TRUE ~ collection_date),
           time = case_when(is.na(time) ~ strftime(strptime("115900", "%H%M%S"), "%H:%M:%S"), 
                          TRUE ~ time),
          evacuation_time = strftime(strptime("115900", "%H%M%S"), "%H:%M:%S")) %>% #if no time recorded in the metadata sheet, fill in with noon
   mutate(evacuation_date = case_when(
    is.na(evacuation_date) & str_detect(collection_date, "2022-05-18") ~ as.Date("2022-05-12"),
    is.na(evacuation_date) & str_detect(collection_date, "2022-05-20")  ~ as.Date("2022-05-12"), 
    is.na(evacuation_date) & str_detect(collection_date, "2022-06-13")  ~ as.Date("2022-06-09"),
    is.na(evacuation_date) & str_detect(collection_date, "2022-06-15")  ~ as.Date("2022-06-09"),
    is.na(evacuation_date) & str_detect(collection_date, "2022-06-20") ~ as.Date("2022-06-18"),
    is.na(evacuation_date) & str_detect(collection_date, "2022-06-22") ~ as.Date("2022-06-22"),
    is.na(evacuation_date) & str_detect(collection_date, "2022-06-23") ~ as.Date("2022-06-22"),
    is.na(evacuation_date) & str_detect(collection_date, "2022-06-24") ~ as.Date("2022-06-23"),
    is.na(evacuation_date) & str_detect(collection_date, "2022-07-18") ~ as.Date("2022-07-14"),
    is.na(evacuation_date) & str_detect(collection_date, "2022-07-21") ~ as.Date("2022-07-18"),
    is.na(evacuation_date) & str_detect(collection_date, "2023-06-05") ~ as.Date("2023-06-03"),
    is.na(evacuation_date) & str_detect(collection_date, "2023-10-05") ~ as.Date("2023-10-02"),
    TRUE ~ evacuation_date)) %>%
      mutate(evacuation_datetime = case_when(is.na(evacuation_datetime) ~ as.POSIXct(paste(evacuation_date, evacuation_time), format = "%Y-%m-%d %H:%M:%S"), TRUE ~ evacuation_datetime),
       collection_datetime = case_when(is.na(collection_datetime) ~ as.POSIXct(paste(collection_date, time), format = "%Y-%m-%d %H:%M:%S"), TRUE ~ collection_datetime),
  elapsed_time = difftime(collection_datetime, evacuation_datetime, units= "hours")) 

#### FILTER TO POOLED ONLY: ####

porewater_pooled_wmeta <-npoc_wflags_metadata.1 %>%
  filter(Grid == "POOL") %>%
  left_join(pooled_sample_key_merging, by= c("sample_name","Plot","Grid","date"))

#### FILTER TO SOURCE WATER ONLY: ####

sourcewater_wmeta <-npoc_wflags_metadata.1 %>%
  filter(grepl("SOURCE|ESTUARY|BARGE", sample_name))

```

```{r troubleshooting metadata}

missing_meta <- porewater_grids_wmeta %>%
  filter(is.na(evacuation_date)) %>%
  filter(is.na(Timepoint)) %>%
  filter(date < as.POSIXct("2022-06-01 00:00:00", tz = "EST") | date > as.POSIXct("2022-06-30 00:00:00", tz = "EST")) # I know we are already missing the event dates/times from 2022 event, so filter these out for now. 

missing_meta

# This is whats missing: 

  # TMP_SW_E3_20220808 doesn't exist in the metadata but we have DOC for this. Assuming it was just missed from metadata entry and will fill down the metadata values later on.
  # TMP_FW_F4_20220915 doesn't exist in the metadata but we have DOC for this. Assuming it was just missed from metadata entry and will fill down the metadata values later on.
   # TMP_C_C6_20221019 doesn't exist in the metadata for DOC, but we have DOC for this. Assuming it was just missed from metadata entry and will fill down the metadata values later on.
  # TMP_SW_H6_20230417 doesn't exist in the metadata for DOC, but we have DOC for this. Assuming it was just missed from metadata entry and will fill down the metadata values later on.
  # TMP_FW_D5_20230605 doesn't exist in the metadata for DOC, but we have DOC for this. Assuming it was just missed from metadata entry and will fill in the metadata values later on.
  # TMP_SW_H6_20230612 doesn't exist in the metadata for DOC, but we have DOC for this. Assuming it was just missed from metadata entry and will fill in the metadata values later on.
  # TMP_C_C3_20230628 doesn't exist in the metadata for DOC, but we have DOC for this. Assuming it was just missed from metadata entry and will fill in the metadata values later on.
  # We have both TMP_C_H6_20230807 and TMP_C_H6_20230810 in the DOC data but only TMP_C_H6_20230807 in the metadata. Assuming TMP_C_H6_20230810 was just missed from metadata entry and will fill in the metadata values later on.
  # We have both TMP_SW_I5_20230807 and TMP_SW_I5_20230810 in the DOC data but only TMP_SW_I5_20230810 in the metadata. Assuming TMP_SW_I5_20230807 was just missed from metadata entry and will fill in the metadata values later on.
  # We have both TMP_SW_C6_20230807 and TMP_SW_C6_20230810 in the DOC data but only TMP_SW_C6_20230807 in the metadata. Assuming TMP_SW_C6_20230810 was just missed from metadata entry and will fill in the metadata values later on.
  # Same story for TMP_SW_H3_20230810 & TMP_SW_E3_20230810
```

```{r fill in missing grid metadata}

porewater_grids_wmeta_filled <- porewater_grids_wmeta %>%
  group_by(Plot, Grid, collection_date) %>%
  mutate(evacuation_date = case_when(
    is.na(evacuation_date) & str_detect(collection_date, "2022-08-08") ~ as.Date("2022-08-05"),
    is.na(evacuation_date) & str_detect(collection_date, "2022-09-15")  ~ as.Date("2022-09-12"), 
    is.na(evacuation_date) & str_detect(collection_date, "2022-10-19")  ~ as.Date("2022-10-17"),
    is.na(evacuation_date) & str_detect(collection_date, "2023-04-17")  ~ as.Date("2023-04-14"),
    is.na(evacuation_date) & str_detect(collection_date, "2023-06-12") ~ as.Date("2023-06-08"),
    is.na(evacuation_date) & str_detect(collection_date, "2023-06-28") ~ as.Date("2023-06-23"),
    is.na(evacuation_date) & str_detect(collection_date, "2023-08-07") ~ as.Date("2023-08-04"),
    is.na(evacuation_date) & str_detect(collection_date, "2023-08-10") ~ as.Date("2023-08-07"),
    is.na(evacuation_date) & str_detect(collection_date, "2023-12-11") ~ as.Date("2023-12-08"),
    TRUE ~ evacuation_date)) %>%
      mutate(evacuation_datetime = case_when(is.na(evacuation_datetime) ~ as.POSIXct(paste(evacuation_date, evacuation_time), format = "%Y-%m-%d %H:%M:%S"), TRUE ~ evacuation_datetime),
       collection_datetime = case_when(is.na(collection_datetime) ~ as.POSIXct(paste(collection_date, time), format = "%Y-%m-%d %H:%M:%S"), TRUE ~ collection_datetime),
  elapsed_time = difftime(collection_datetime, evacuation_datetime, units= "hours")) %>%
    mutate(set_tz = with_tz(collection_datetime, tzone = "America/New_York"),
         is_dst = dst(set_tz),
    tz = case_when(is.na(tz) &  is_dst == TRUE ~ "EDT",
                   is.na(tz) &  is_dst != TRUE ~ "EST",
                   TRUE ~ tz)) %>%
  dplyr::select(-set_tz, -is_dst)
```

# Pull out and save the grid volumes - don't need to write this into the L1 DOC dataframe.
***Note, this is set up if you run the markdown that it won't actually save the files, to prevent folks from overwritting version of record files when getting familiar with the script.*** 

```{r grid volumes, eval=FALSE}

grid_volumes <- porewater_grids_wmeta_filled %>% 
  filter(collection_date < endstudydate & collection_date > startstudydate) %>%
  select(Plot, Grid, Total_Aliquot_Volume_mL, evacuation_date, collection_date) %>%
  drop_na() #remove rows where we don't have the volume information in this sheet

saveRDS(grid_volumes, "~/GitHub/TEMPEST-1-porewater/processed data/TMP_PW_Aliquots_Volumes.rds")

```

```{r dataframe clean up for write out}

pwsite_key_all <- pwsite_key %>% tidyr::expand(Plot, Grid, date = unique(porewater_grids_wmeta_filled$date)) %>% drop_na() %>%
  mutate(Plot = case_when(Plot == "FW" ~ "Freshwater",
                          Plot == "C" ~ "Control",
                          Plot == "SW" ~ "Saltwater",
                          TRUE ~ Plot)) %>%
  mutate(date = lubridate::as_date(date, format = "%Y%m%d"))

clean_porewater_grids_wmeta_filled <- porewater_grids_wmeta_filled %>%
  #remove columns we don't need anymore
  select(-Total_Aliquot_Volume_mL) %>%
  full_join(pwsite_key_all, by=c("Plot","Grid", "date")) %>%  #gap fill with NAs when lysimeters were dry for that sampling timepoint
    filter(date < endstudydate & date > startstudydate) %>%
  mutate(doc_mg_l = case_when(is.na(sample_name) & is.na(rundate) ~ NA,
                              TRUE ~ doc_mg_l),
         tdn_mg_l = case_when(is.na(sample_name) & is.na(rundate) ~ NA,
                              TRUE ~ tdn_mg_l),
         Event = case_when(is.na(Event) ~ "TMP",
                           TRUE ~ Event),
         sample_name = case_when(is.na(sample_name)~ "Lysimeter Empty",
                                 TRUE ~ sample_name)) %>%
   mutate(Group=case_when(lubridate::month(date) != 6 ~ as.character(paste(lubridate::year(date), lubridate::month(date), 1, sep = "-")),
                         lubridate::month(date) == 6 ~ as.character(date)))%>%
  mutate(Group = lubridate::as_date(Group)) %>%
  group_by(date) %>%
  arrange(desc(date), .by_group = TRUE) %>%
  fill(time, tz, evacuation_date, collection_date, evacuation_datetime, collection_datetime, elapsed_time, evacuation_time) 

porewater_grids_L1 <- clean_porewater_grids_wmeta_filled %>%
  rename(plot = Plot,
         grid = Grid,
         site = Event,
         doc_flag = npoc_flag) %>%
  select(site, plot, grid, sample_name, evacuation_datetime, collection_datetime, tz, doc_mg_l, tdn_mg_l, doc_flag, tdn_flag)

```

Need to get pooled volumes for 2022 event to finish cleaning pooled dataframe:
```{r pooled volumes 2022}
pooled_2022_vols <- readRDS("~/GitHub/tempest-system-level-analysis/data/for processing/tmp_2022_event_pooled_pw_volumes_tidy.rds") %>%
  select(Plot, Timepoint, Date, Grid, Pooled, total_pooled_volume) %>%
  pivot_wider(names_from = c(Grid), names_prefix = "Pooled_vol_mL_from_", values_from = c(Pooled)) %>%
  rename(date = Date,
         Total_Volume_mL = total_pooled_volume) %>%
   mutate(Plot = case_when(Plot == "C" ~ "Control",
                           Plot == "SW" ~ "Saltwater",
                           Plot == "FW" ~ "Freshwater",
                          TRUE ~ Plot))
  
```

```{r cleaning data for pooled sample type}

#Only porewater POOLED, all dates:
pooled_L1_all <- porewater_pooled_wmeta %>% #these were pooled in lab and metadata not documented, so drop:
  filter(date != "20220523") %>%
   mutate(date = lubridate::as_date(date, format = "%Y%m%d")) %>%
    left_join(pooled_2022_vols, by= c("Plot","Timepoint","date"), suffix = c("", ".fill")) %>%
  #cant get this to work dynamically so, doing it the long way: 
    mutate(Total_Volume_mL = coalesce(Total_Volume_mL, Total_Volume_mL.fill),
           Pooled_vol_mL_from_C3 = coalesce(Pooled_vol_mL_from_C3, Pooled_vol_mL_from_C3.fill),
           Pooled_vol_mL_from_C6 = coalesce(Pooled_vol_mL_from_C6, Pooled_vol_mL_from_C6.fill),
           Pooled_vol_mL_from_F4 = coalesce(Pooled_vol_mL_from_F4, Pooled_vol_mL_from_F4.fill),
           Pooled_vol_mL_from_H3 = coalesce(Pooled_vol_mL_from_H3, Pooled_vol_mL_from_H3.fill),
           Pooled_vol_mL_from_H6 = coalesce(Pooled_vol_mL_from_H6, Pooled_vol_mL_from_H6.fill),
           Pooled_vol_mL_from_B4 = coalesce(Pooled_vol_mL_from_B4, Pooled_vol_mL_from_B4.fill),
           Pooled_vol_mL_from_D5 = coalesce(Pooled_vol_mL_from_D5, Pooled_vol_mL_from_D5.fill),
           Pooled_vol_mL_from_E3 = coalesce(Pooled_vol_mL_from_E3, Pooled_vol_mL_from_E3.fill),
           Pooled_vol_mL_from_F6 = coalesce(Pooled_vol_mL_from_F6, Pooled_vol_mL_from_F6.fill),
           Pooled_vol_mL_from_I5 = coalesce(Pooled_vol_mL_from_I5, Pooled_vol_mL_from_I5.fill)) %>%
  select(-contains(".fill")) %>%
  mutate(collection_date = case_when(is.na(collection_date) ~ date,
                  TRUE ~ collection_date)) %>% #if no time recorded in the metadata sheet, fill in with noon
   mutate(evacuation_date = case_when(
    is.na(evacuation_date) & str_detect(collection_date, "2022-06-20") ~ as.Date("2022-06-18"),
    is.na(evacuation_date) & str_detect(collection_date, "2022-06-22") ~ as.Date("2022-06-22"),
    is.na(evacuation_date) & str_detect(collection_date, "2022-06-23") ~ as.Date("2022-06-22"),
    is.na(evacuation_date) & str_detect(collection_date, "2022-06-24") ~ as.Date("2022-06-23"),
    TRUE ~ evacuation_date)) %>%
    filter(date < endstudydate & date > startstudydate) %>%
    rename(plot = Plot,
         grid = Grid,
         site = Event,
         doc_flag = npoc_flag) %>%
  select(site, plot, grid, date, evacuation_date, collection_date, Total_Volume_mL, Pooled_vol_mL_from_C3:Pooled_vol_mL_from_F6, doc_mg_l, tdn_mg_l, doc_flag, tdn_flag)
 
```

```{r cleaning data for source water sample type}

#Only sourcewater, all dates:
source_L1_all <- sourcewater_wmeta %>%
     mutate(time.1 = case_when(is.na(time) ~ stringr::str_extract(sample_name, "(?<=[0-9]{8}_)\\d{4}"),                           TRUE ~ time),
            time.1 = str_replace(time.1, '\\d+', function(m) str_pad(m, 6, pad = '0', side = ("right")))) %>% 
     mutate(time = case_when(is.na(time) ~ time.1, 
                             TRUE ~ time)) %>%
     mutate(time = case_when(is.na(time) ~ "115900", 
                             TRUE ~ time)) %>%  #if no time recorded in the metadata sheet, fill in with noon 
  select(-time.1) %>%
  mutate(time= strptime(time, format ="%H%M%S"), 
         time = strftime(time, "%H:%M:%S")) %>%
    mutate(date = lubridate::as_date(date, format = "%Y%m%d")) %>%
    filter(date < endstudydate & date > startstudydate) %>%
   mutate(datetime = as.POSIXct(paste(date, time), format = "%Y-%m-%d %H:%M:%S"))%>%
  rename(plot = Plot,
         grid = Grid,
         site = Event,
         doc_flag = npoc_flag) %>%
  select(site, plot, grid, datetime, doc_mg_l, tdn_mg_l, doc_flag, tdn_flag)


```


# Write data

***Note, this is set up if you run the markdown that it won't actually save the files, to prevent folks from overwritting version of record files when getting familiar with the script.*** 

## Write for Google Drive L1

Naming:
SITE_SAMPLETYPE_ORG_ANALYSISTYPE_YEAR_LEVEL.csv 
Include ORG only if applicable 

```{r write sourewater, eval=FALSE}

l1_sourcewater_2022 = source_L1_all %>%
   filter(datetime < year1_stop & datetime > year1_start)

write_csv(l1_sourcewater_2022, "~/GitHub/TEMPEST_Porewater/processing_scripts/DOC/TEMPORARY/TMP_SOURCE_NPOCTDN_2022_L1.csv")

l1_sourcewater_2023 = source_L1_all %>%
   filter(datetime < year2_stop & datetime > year2_start)

write_csv(l1_sourcewater_2023, "~/GitHub/TEMPEST_Porewater/processing_scripts/DOC/TEMPORARY/TMP_SOURCE_NPOCTDN_2023_L1.csv")

```

Naming:
SITE_SAMPLETYPE_ORG_ANALYSISTYPE_YEAR_LEVEL.csv 
Include ORG only if applicable 

```{r write porewater grids, eval=FALSE}

l1_porewater_2022 = porewater_grids_L1 %>%
   filter(collection_datetime < year1_stop & collection_datetime > year1_start)

write_csv(l1_porewater_2022, "~/GitHub/TEMPEST-1-porewater/processed data/for_google_drive/TMP_PW_GRIDSONLY_NPOCTDN_2022_L1.csv")

write_csv(l1_porewater_2022, "~/GitHub/TEMPEST_Porewater/processing_scripts/DOC/TEMPORARY/TMP_PW_GRIDSONLY_NPOCTDN_2022_L1.csv")

l1_porewater_2023 = porewater_grids_L1 %>%
   filter(collection_datetime < year2_stop & collection_datetime > year2_start)

write_csv(l1_porewater_2023, "~/GitHub/TEMPEST-1-porewater/processed data/for_google_drive/TMP_PW_GRIDSONLY_NPOCTDN_2023_L1.csv")

write_csv(l1_porewater_2023, "~/GitHub/TEMPEST_Porewater/processing_scripts/DOC/TEMPORARY/TMP_PW_GRIDSONLY_NPOCTDN_2023_L1.csv")


```

```{r write pooled, eval=FALSE}

l1_pooled_2022 = pooled_L1_all %>%
   filter(date < year1_stop & date > year1_start)

write_csv(l1_pooled_2022, "~/GitHub/TEMPEST_Porewater/processing_scripts/DOC/TEMPORARY/TMP_PW_POOLED_NPOCTDN_2022_L1.csv")

l1_pooled_2023 = pooled_L1_all %>%
   filter(date < year2_stop & date > year2_start)

write_csv(l1_pooled_2023, "~/GitHub/TEMPEST_Porewater/processing_scripts/DOC/TEMPORARY/TMP_PW_POOLED_NPOCTDN_2023_L1.csv")

```

<!-- # npoc_wflags_metadata <- npoc_wflags_metadata.1 %>% -->
<!-- #    full_join(pwsite_key_all, by=c("Plot","Grid", "date")) %>%  #gap fill with NAs when lysimeters were dry for that sampling timepoint -->
<!-- #   mutate(time = case_when(is.na(time) ~ stringr::str_extract(sample_name, "(?<=[0-9]{8}_)\\d{4}"), -->
<!-- #                           TRUE ~ time), -->
<!-- #          time = str_replace(time, '\\d+', function(m) str_pad(m, 6, pad = '0', side = ("right"))) -->
<!-- #          ) %>% -->
<!-- #   mutate(time = case_when(is.na(time) ~ "115900",  -->
<!-- #                           TRUE ~ time)) %>% #if no time recorded in the metadata sheet, fill in with noon -->
<!-- #   mutate(time= strptime(time, format ="%H%M%S"), -->
<!-- #          time = strftime(time, "%H:%M:%S")) %>% -->
<!-- #    mutate(Timepoint = case_when(is.na(Timepoint) & date == "2022-07-18" ~ "T5", -->
<!-- #                              is.na(Timepoint) & date == "2022-07-21" ~ "T5", -->
<!-- #                              is.na(Timepoint) & date == "2022-06-15" ~ "T0", -->
<!-- #                                       TRUE ~ Timepoint), -->
<!-- #                date = case_when(is.na(sample_name) & Timepoint == "T0" ~ lubridate::as_date("2022-06-20"), -->
<!-- #                           is.na(sample_name) & Timepoint == "T1" ~ lubridate::as_date("2022-06-22"), -->
<!-- #                           is.na(sample_name) & Timepoint == "T2" ~ lubridate::as_date("2022-06-22"), -->
<!-- #                           is.na(sample_name) & Timepoint == "T3" ~ lubridate::as_date("2022-06-23"), -->
<!-- #                           is.na(sample_name) & Timepoint == "T4" ~ lubridate::as_date("2022-06-24"), -->
<!-- #                           is.na(sample_name) & Timepoint == "T5" ~ lubridate::as_date("2022-07-21"), -->
<!-- #                           TRUE ~ date)) %>% -->
<!-- #   mutate(datetime = as.POSIXct(paste(date, time), format = "%Y-%m-%d %H:%M:%S")) -->
<!-- #  -->
<!-- # print(npoc_wflags_metadata) -->

<!-- # ```{r manuscript specific final write out of pw, eval=FALSE} -->
<!-- # for_fluxes <- PW_npoc_wflags_metadata_grids_only %>% -->
<!-- #   ungroup() %>% -->
<!-- #   rename(grid = Grid, -->
<!-- #          collection_datetime = datetime) %>% -->
<!-- #   select(Event, plot, grid, sample_name, doc_mg_l, tdn_mg_l, evacuation_date, collection_datetime, tz) %>% -->
<!-- #   #manual entry of missing evacuation information from the notes:  -->
<!-- #   mutate(evacuation_date = case_when( -->
<!-- #     is.na(evacuation_date) & str_detect(collection_datetime, "2022-05-18") ~ as.Date("2022-05-12"), -->
<!-- #     is.na(evacuation_date) & str_detect(collection_datetime, "2022-05-20")  ~ as.Date("2022-05-12"),  -->
<!-- #     is.na(evacuation_date) & str_detect(collection_datetime, "2022-06-13")  ~ as.Date("2022-06-09"), -->
<!-- #     is.na(evacuation_date) & str_detect(collection_datetime, "2022-06-15")  ~ as.Date("2022-06-09"), -->
<!-- #     is.na(evacuation_date) & str_detect(collection_datetime, "2022-06-20") ~ as.Date("2022-06-18"), -->
<!-- #     is.na(evacuation_date) & str_detect(collection_datetime, "2022-06-22") ~ as.Date("2022-06-22"), -->
<!-- #     is.na(evacuation_date) & str_detect(collection_datetime, "2022-06-23") ~ as.Date("2022-06-22"), -->
<!-- #     is.na(evacuation_date) & str_detect(collection_datetime, "2022-06-24") ~ as.Date("2022-06-23"), -->
<!-- #     is.na(evacuation_date) & str_detect(collection_datetime, "2023-06-05") ~ as.Date("2023-06-03"), -->
<!-- #     is.na(evacuation_date) & str_detect(collection_datetime, "2023-10-05") ~ as.Date("2023-10-02"), -->
<!-- #     TRUE ~ evacuation_date)) %>% -->
<!-- #   filter(collection_datetime != "2022-05-23 11:59:00") %>% -->
<!-- #   mutate(set_tz = with_tz(collection_datetime, tzone = "America/New_York"), -->
<!-- #          is_dst = dst(set_tz), -->
<!-- #     tz = case_when(is.na(tz) &  is_dst == TRUE ~ "EDT", -->
<!-- #                    is.na(tz) &  is_dst != TRUE ~ "EST", -->
<!-- #                    TRUE ~ tz)) %>% -->
<!-- #   select(-set_tz, -is_dst) -->
<!-- #  -->
<!-- # write_csv(for_fluxes, "~/GitHub/TEMPEST-1-porewater/processed data/TMP_PW_GRIDSONLY_NPOC_TDN_L1_May2022-Dec2023.csv") -->
<!-- #  -->
<!-- # saveRDS(for_fluxes, "~/GitHub/TEMPEST-1-porewater/processed data/TMP_PW_GRIDSONLY_NPOC_TDN_L1_May2022-Dec2023.rds") -->
<!-- # ``` -->
